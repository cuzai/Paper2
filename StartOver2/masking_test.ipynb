{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids_keep: tensor([1, 0])\n",
      "masked_input: tensor([4, 2])\n",
      "____________________________________________________________________________________________________\n",
      "revert: tensor([1, 0, 4, 2, 3])\n",
      "final_input: tensor([4., 2., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 0., 0., 0.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITHOUT PADDING\n",
    "import torch\n",
    "sample = 0.5\n",
    "\n",
    "# WE ARE ON DATALOADER STAGE\n",
    "arr1 = torch.tensor([2,4,6,8,10])#.unsqueeze(-1)\n",
    "num_sample = int(len(arr1) * sample)\n",
    "\n",
    "# Index for shuffle and revert\n",
    "noise = torch.rand(arr1.shape)\n",
    "shuffle = torch.argsort(noise, dim=0)\n",
    "revert = torch.argsort(shuffle, dim=0)\n",
    "\n",
    "# Get keep value\n",
    "idx_keep = shuffle[:num_sample]\n",
    "masked_input = torch.gather(arr1, index=idx_keep, dim=0)\n",
    "print(\"ids_keep:\", idx_keep)\n",
    "print(\"masked_input:\", masked_input) # Order of masked input does not matter since we already pos_encoded the sequence\n",
    "print(\"_\"*100)\n",
    "\n",
    "# Revert\n",
    "final_input = torch.cat([masked_input, torch.zeros(len(arr1) - num_sample)])\n",
    "print(\"revert:\", revert)\n",
    "print(\"final_input:\", final_input)\n",
    "torch.gather(final_input, index=revert, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids_keep: tensor([3, 2])\n",
      "masked_input: tensor([8, 6])\n",
      "padded_input: tensor([8., 6., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "____________________________________________________________________________________________________\n",
      "revert: tensor([3, 4, 1, 0, 2, 9, 9, 9, 9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 6., 8., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITH PADDING\n",
    "max_seq_len = 10\n",
    "mask_value = 0\n",
    "padding_idx = max_seq_len\n",
    "\n",
    "sample = 0.5\n",
    "arr1 = torch.tensor([2,4,6,8,10])#.unsqueeze(-1)\n",
    "num_sample = int(len(arr1) * sample)\n",
    "\n",
    "# Index for shuffle and revert\n",
    "noise = torch.rand(arr1.shape)\n",
    "shuffle = torch.argsort(noise, dim=0)\n",
    "revert = torch.argsort(shuffle, dim=0)\n",
    "\n",
    "# Get keep value\n",
    "idx_keep = shuffle[:num_sample]\n",
    "masked_input = torch.gather(arr1, index=idx_keep, dim=0)\n",
    "print(\"ids_keep:\", idx_keep)\n",
    "print(\"masked_input:\", masked_input) # Order of masked input does not matter since we already pos_encoded the sequence\n",
    "\n",
    "# Padding\n",
    "padded_input = torch.concat([masked_input, torch.zeros(max_seq_len - len(masked_input))+mask_value])\n",
    "print(\"padded_input:\", padded_input)\n",
    "print(\"_\"*100)\n",
    "\n",
    "# Revert\n",
    "revert = torch.cat([revert, torch.zeros(max_seq_len-len(revert)) + (max_seq_len-1)]).to(torch.int64)\n",
    "print(\"revert:\", revert)\n",
    "res = torch.gather(padded_input, index=revert, dim=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids_keep: tensor([0])\n",
      "masked_input: tensor([2])\n",
      "--------------------------------------------------\n",
      "ids_keep: tensor([1, 0])\n",
      "masked_input: tensor([4, 2])\n",
      "--------------------------------------------------\n",
      "ids_keep: tensor([1, 0, 2])\n",
      "masked_input: tensor([4, 2, 6])\n",
      "--------------------------------------------------\n",
      "ids_keep: tensor([0, 2, 3, 4])\n",
      "masked_input: tensor([ 2,  6,  8, 10])\n",
      "--------------------------------------------------\n",
      "padded_input:\n",
      " tensor([[ 2,  0,  0,  0],\n",
      "        [ 4,  2,  0,  0],\n",
      "        [ 4,  2,  6,  0],\n",
      "        [ 2,  6,  8, 10]])\n",
      "revert:\n",
      " tensor([[0, 1, 4, 4, 4],\n",
      "        [1, 0, 2, 4, 4],\n",
      "        [1, 0, 2, 3, 4],\n",
      "        [0, 4, 1, 2, 3]])\n",
      "____________________________________________________________________________________________________\n",
      "max_seq_len: 5\n",
      "filled_input:\n",
      " tensor([[ 2.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 4.,  2.,  0.,  0.,  0.,  0.],\n",
      "        [ 4.,  2.,  6.,  0.,  0.,  0.],\n",
      "        [ 2.,  6.,  8., 10.,  0.,  0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  0.,  0.,  0.,  0.],\n",
       "        [ 2.,  4.,  0.,  0.,  0.],\n",
       "        [ 2.,  4.,  6.,  0.,  0.],\n",
       "        [ 2.,  0.,  6.,  8., 10.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MULTIPLE DIMENSTIONS\n",
    "# WITH PADDING\n",
    "mask_value = 0\n",
    "\n",
    "sample = 0.9\n",
    "arr1 = torch.tensor([2,4])\n",
    "arr2 = torch.tensor([2,4,6])\n",
    "arr3 = torch.tensor([2,4,6,8])\n",
    "arr4 = torch.tensor([2,4,6,8,10])\n",
    "\n",
    "arr_li = [arr1, arr2, arr3, arr4]\n",
    "revert_li = []\n",
    "masked_input_li = []\n",
    "max_seq_len = 0\n",
    "\n",
    "for i in range(len(arr_li)):\n",
    "    num_sample = int(len(arr_li[i]) * sample)\n",
    "\n",
    "    # Index for shuffle and revert\n",
    "    noise = torch.rand(arr_li[i].shape)\n",
    "    shuffle = torch.argsort(noise, dim=0)\n",
    "    revert = torch.argsort(shuffle, dim=0)\n",
    "    max_seq_len = len(revert) if len(revert)>max_seq_len else max_seq_len\n",
    "    revert_li.append(revert)\n",
    "    \n",
    "\n",
    "    # Get keep value\n",
    "    idx_keep = shuffle[:num_sample]\n",
    "    masked_input = torch.gather(arr_li[i], index=idx_keep, dim=0)\n",
    "    masked_input_li.append(masked_input)\n",
    "    print(\"ids_keep:\", idx_keep)\n",
    "    print(\"masked_input:\", masked_input) # Order of masked input does not matter since we already pos_encoded the sequence\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Padding\n",
    "padded_input = torch.nn.utils.rnn.pad_sequence(masked_input_li, batch_first=True)\n",
    "revert = torch.nn.utils.rnn.pad_sequence(revert_li, batch_first=True, padding_value=max_seq_len-1)\n",
    "print(\"padded_input:\\n\", padded_input)\n",
    "print(\"revert:\\n\", revert)\n",
    "print(\"_\"*100)\n",
    "\n",
    "# Revert\n",
    "print(\"max_seq_len:\", max_seq_len)\n",
    "filled_input = torch.concat([padded_input, torch.zeros(padded_input.shape[0], (max_seq_len - padded_input.shape[1]+1))], dim=1)\n",
    "print(\"filled_input:\\n\", filled_input)\n",
    "torch.gather(filled_input, index=revert, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr:\n",
      " tensor([[ 2,  4,  0,  0,  0],\n",
      "        [ 2,  4,  6,  0,  0],\n",
      "        [ 2,  4,  6,  8,  0],\n",
      "        [ 2,  4,  6,  8, 10]])\n",
      "keep_idx:\n",
      " tensor([[0, 4],\n",
      "        [2, 4],\n",
      "        [1, 3],\n",
      "        [1, 4]])\n",
      "revert_idx:\n",
      " tensor([[0, 1, 4, 4, 4],\n",
      "        [2, 1, 0, 4, 4],\n",
      "        [3, 0, 2, 1, 4],\n",
      "        [2, 0, 4, 3, 1]])\n",
      "____________________________________________________________________________________________________\n",
      "masked_input:\n",
      " tensor([[ 2,  0],\n",
      "        [ 6,  0],\n",
      "        [ 4,  8],\n",
      "        [ 4, 10]])\n",
      "filled_input:\n",
      " tensor([[ 2.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 6.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 4.,  8.,  0.,  0.,  0.,  0.],\n",
      "        [ 4., 10.,  0.,  0.,  0.,  0.]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  6.,  0.,  0.],\n",
       "        [ 0.,  4.,  0.,  8.,  0.],\n",
       "        [ 0.,  4.,  0.,  0., 10.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# MULTIPLE DIMENSTIONS\n",
    "# WITH PADDING\n",
    "mask_value = 0\n",
    "\n",
    "sample = 0.5\n",
    "arr1 = torch.tensor([2,4])\n",
    "arr2 = torch.tensor([2,4,6])\n",
    "arr3 = torch.tensor([2,4,6,8])\n",
    "arr4 = torch.tensor([2,4,6,8,10])\n",
    "\n",
    "arr_li = [arr1, arr2, arr3, arr4]\n",
    "revert_li = []\n",
    "keep_li = []\n",
    "max_seq_len = 0\n",
    "\n",
    "for i in range(len(arr_li)):\n",
    "    num_sample = int(len(arr_li[i]) * sample)\n",
    "\n",
    "    # Index for shuffle and revert\n",
    "    noise = torch.rand(arr_li[i].shape)\n",
    "    shuffle = torch.argsort(noise, dim=0)\n",
    "    revert = torch.argsort(shuffle, dim=0)\n",
    "    max_seq_len = len(revert) if len(revert)>max_seq_len else max_seq_len\n",
    "    revert_li.append(revert)\n",
    "\n",
    "    # Get keep value\n",
    "    idx_keep = shuffle[:num_sample]\n",
    "    keep_li.append(idx_keep)\n",
    "\n",
    "# Padding\n",
    "arr = torch.nn.utils.rnn.pad_sequence(arr_li, batch_first=True)\n",
    "keep = torch.nn.utils.rnn.pad_sequence(keep_li, batch_first=True, padding_value=max_seq_len-1)\n",
    "revert = torch.nn.utils.rnn.pad_sequence(revert_li, batch_first=True, padding_value=max_seq_len-1)\n",
    "print(\"arr:\\n\", arr)\n",
    "print(\"keep_idx:\\n\", keep)\n",
    "print(\"revert_idx:\\n\", revert)\n",
    "print(\"_\"*100)\n",
    "\n",
    "# Select\n",
    "# Todo: Linear trnasform & pos_encoding\n",
    "masked_input = torch.gather(arr, index=keep, dim=-1)\n",
    "print(\"masked_input:\\n\", masked_input)\n",
    "\n",
    "# Revert\n",
    "filled_input = torch.concat([masked_input, torch.zeros(masked_input.shape[0], (max_seq_len - masked_input.shape[1]+1))], dim=1)\n",
    "print(\"filled_input:\\n\", filled_input)\n",
    "print()\n",
    "torch.gather(filled_input, index=revert, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr:\n",
      " tensor([[ 2,  4,  0,  0,  0],\n",
      "        [ 2,  4,  6,  0,  0],\n",
      "        [ 2,  4,  6,  8,  0],\n",
      "        [ 2,  4,  6,  8, 10]])\n",
      "keep:\n",
      " tensor([[1, 0],\n",
      "        [2, 0],\n",
      "        [1, 2],\n",
      "        [0, 4]])\n",
      "revert_idx:\n",
      " tensor([[1, 0, 0, 0, 0],\n",
      "        [2, 1, 0, 0, 0],\n",
      "        [2, 0, 1, 3, 0],\n",
      "        [0, 3, 4, 2, 1]])\n",
      "____________________________________________________________________________________________________\n",
      "masked_input:\n",
      " tensor([[ 4, 99],\n",
      "        [ 6, 99],\n",
      "        [ 4,  6],\n",
      "        [ 2, 10]])\n",
      "keep_mask\n",
      " tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "____________________________________________________________________________________________________\n",
      "filled_input:\n",
      " tensor([[ 4., 99., 99., 99., 99., 99.],\n",
      "        [ 6., 99., 99., 99., 99., 99.],\n",
      "        [ 4.,  6., 99., 99., 99., 99.],\n",
      "        [ 2., 10., 99., 99., 99., 99.]])\n",
      "____________________________________________________________________________________________________\n",
      "tensor([[99.,  4.,  4.,  4.,  4.],\n",
      "        [99., 99.,  6.,  6.,  6.],\n",
      "        [99.,  4.,  6., 99.,  4.],\n",
      "        [ 2., 99., 99., 99., 10.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 99.,   4., -99., -99., -99.],\n",
       "        [ 99.,  99.,   6., -99., -99.],\n",
       "        [ 99.,   4.,   6.,  99., -99.],\n",
       "        [  2.,  99.,  99.,  99.,  10.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we need special mask token?\n",
    "\n",
    "import torch\n",
    "# MULTIPLE DIMENSTIONS\n",
    "# WITH PADDING\n",
    "mask_value = 99\n",
    "padding_value = -99\n",
    "\n",
    "sample = 0.5\n",
    "arr1 = torch.tensor([2,4])\n",
    "arr2 = torch.tensor([2,4,6])\n",
    "arr3 = torch.tensor([2,4,6,8])\n",
    "arr4 = torch.tensor([2,4,6,8,10])\n",
    "\n",
    "arr_li = [arr1, arr2, arr3, arr4]\n",
    "\n",
    "keep_li = []\n",
    "keep_mask_li = []\n",
    "\n",
    "revert_li = []\n",
    "revert_mask_li = []\n",
    "\n",
    "for i in range(len(arr_li)):\n",
    "    num_sample = int(len(arr_li[i]) * sample)\n",
    "\n",
    "    # Index for shuffle and revert\n",
    "    noise = torch.rand(arr_li[i].shape)\n",
    "    shuffle = torch.argsort(noise, dim=0)\n",
    "    revert = torch.argsort(shuffle, dim=0)\n",
    "    revert_li.append(revert)\n",
    "    revert_mask_li.append(torch.ones(revert.shape))\n",
    "\n",
    "    # Get keep value\n",
    "    idx_keep = shuffle[:num_sample]\n",
    "    keep_li.append(idx_keep)\n",
    "    keep_mask_li.append(torch.ones(idx_keep.shape))\n",
    "\n",
    "# Padding\n",
    "arr = torch.nn.utils.rnn.pad_sequence(arr_li, batch_first=True)\n",
    "keep = torch.nn.utils.rnn.pad_sequence(keep_li, batch_first=True)\n",
    "keep_mask = torch.nn.utils.rnn.pad_sequence(keep_mask_li, batch_first=True)\n",
    "revert = torch.nn.utils.rnn.pad_sequence(revert_li, batch_first=True)\n",
    "revert_mask = torch.nn.utils.rnn.pad_sequence(revert_mask_li, batch_first=True)\n",
    "\n",
    "print(\"arr:\\n\", arr)\n",
    "print(\"keep:\\n\", keep)\n",
    "print(\"revert_idx:\\n\", revert)\n",
    "print(\"_\"*100)\n",
    "\n",
    "# Select\n",
    "# Todo: Linear trnasform & pos_encoding\n",
    "masked_input = torch.gather(arr, index=keep, dim=-1)\n",
    "masked_input = torch.where(keep_mask==1, masked_input, mask_value)\n",
    "print(\"masked_input:\\n\", masked_input)\n",
    "print(\"keep_mask\\n\", keep_mask)\n",
    "print(\"_\"*100)\n",
    "\n",
    "# Revert\n",
    "filled_input = torch.concat([masked_input, torch.zeros(masked_input.shape[0], (revert_mask.shape[1] - masked_input.shape[1]+1))+mask_value], dim=1)\n",
    "print(\"filled_input:\\n\", filled_input)\n",
    "print(\"_\"*100)\n",
    "res = torch.gather(filled_input, index=revert, dim=-1)\n",
    "print(res)\n",
    "torch.where(revert_mask == 1, res, padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr:\n",
      " tensor([[ 2,  4,  0,  0,  0],\n",
      "        [ 2,  4,  6,  0,  0],\n",
      "        [ 2,  4,  6,  8,  0],\n",
      "        [ 2,  4,  6,  8, 10]])\n",
      "____________________________________________________________________________________________________\n",
      "remain_arr:\n",
      " tensor([[ 4, 99],\n",
      "        [ 4, 99],\n",
      "        [ 4,  8],\n",
      "        [ 2, 10]])\n",
      "____________________________________________________________________________________________________\n",
      "reverted_arr:\n",
      " tensor([[ 0.,  4., -inf, -inf, -inf],\n",
      "        [ 0.,  4.,  0., -inf, -inf],\n",
      "        [ 0.,  4.,  0.,  8., -inf],\n",
      "        [ 2.,  0.,  0.,  0., 10.]])\n"
     ]
    }
   ],
   "source": [
    "# Do we need special mask token?\n",
    "\n",
    "import torch\n",
    "# MULTIPLE DIMENSTIONS\n",
    "# WITH PADDING\n",
    "mask_value = 99\n",
    "padding_value = -99\n",
    "\n",
    "rto = 0.5\n",
    "arr1 = torch.tensor([2,4])\n",
    "arr2 = torch.tensor([2,4,6])\n",
    "arr3 = torch.tensor([2,4,6,8])\n",
    "arr4 = torch.tensor([2,4,6,8,10])\n",
    "\n",
    "arr_li = [arr1, arr2, arr3, arr4]\n",
    "\n",
    "remain_idx_li = []\n",
    "remain_padding_mask_li = []\n",
    "\n",
    "revert_idx_li = []\n",
    "revert_padding_mask_li = []\n",
    "\n",
    "masked_idx_li = []\n",
    "masked_padding_mask_li = []\n",
    "\n",
    "for i in range(len(arr_li)):\n",
    "    num_remain = int(len(arr_li[i]) * rto)\n",
    "\n",
    "    # Index for shuffle and revert\n",
    "    noise = torch.rand(arr_li[i].shape)\n",
    "    shuffle = torch.argsort(noise, dim=0)\n",
    "    \n",
    "    # Get revert\n",
    "    revert_idx = torch.argsort(shuffle, dim=0)\n",
    "    revert_idx_li.append(revert_idx)\n",
    "    revert_padding_mask_li.append(torch.ones(revert_idx.shape))\n",
    "\n",
    "    # Get remain\n",
    "    remain_idx = shuffle[:num_remain]\n",
    "    remain_idx_li.append(remain_idx)\n",
    "    remain_padding_mask_li.append(torch.ones(remain_idx.shape))\n",
    "    \n",
    "    # Get mask \n",
    "    masked_idx = shuffle[num_remain:]\n",
    "    masked_idx_li.append(masked_idx)\n",
    "    masked_padding_mask_li.append(torch.ones(masked_idx.shape))\n",
    "\n",
    "# Padding\n",
    "arr = torch.nn.utils.rnn.pad_sequence(arr_li, batch_first=True)\n",
    "remain_idx = torch.nn.utils.rnn.pad_sequence(remain_idx_li, batch_first=True)\n",
    "remain_padding_mask = torch.nn.utils.rnn.pad_sequence(remain_padding_mask_li, batch_first=True)\n",
    "revert_idx = torch.nn.utils.rnn.pad_sequence(revert_idx_li, batch_first=True)\n",
    "revert_padding_mask = torch.nn.utils.rnn.pad_sequence(revert_padding_mask_li, batch_first=True)\n",
    "masked_idx = torch.nn.utils.rnn.pad_sequence(masked_idx_li, batch_first=True)\n",
    "masked_padding_mask = torch.nn.utils.rnn.pad_sequence(masked_padding_mask_li, batch_first=True)\n",
    "\n",
    "\n",
    "def apply_remain(data, remain_idx, remain_padding_mask):\n",
    "    remain_data = torch.gather(data, index=remain_idx, dim=-1)\n",
    "    remain_data = torch.where(remain_padding_mask==1, remain_data, 99)\n",
    "    return remain_data\n",
    "        \n",
    "print(\"arr:\\n\", arr)\n",
    "remain_arr = apply_remain(arr, remain_idx, remain_padding_mask)\n",
    "print(\"_\"*100)\n",
    "print(\"remain_arr:\\n\", remain_arr)\n",
    "\n",
    "def apply_revert(remain_data, remain_padding_mask, masked_idx, revert_idx, revert_padding_mask):\n",
    "    # Mask token\n",
    "    mask_token = torch.zeros([1])\n",
    "    \n",
    "    # Replace remain padding mask to mask token\n",
    "    remain_data = torch.where(remain_padding_mask==1, remain_data, mask_token)\n",
    "    \n",
    "    # Make full data\n",
    "    mask_token = mask_token.unsqueeze(0).repeat(remain_data.shape[0], masked_idx.shape[-1])\n",
    "    full_data = torch.cat([remain_data, mask_token], dim=-1)\n",
    "    \n",
    "    # Revert\n",
    "    reverted_data = torch.gather(full_data, index=revert_idx, dim=-1)\n",
    "    reverted_data = torch.where(revert_padding_mask==1, reverted_data, -torch.inf)\n",
    "    return reverted_data\n",
    "\n",
    "reverted_arr = apply_revert(remain_arr, remain_padding_mask, masked_idx, revert_idx, revert_padding_mask)\n",
    "print(\"_\"*100)\n",
    "print(\"reverted_arr:\\n\", reverted_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
