{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_forecasting as pf\n",
    "from pytorch_forecasting.models.base_model import BaseModelWithCovariates\n",
    "\n",
    "from transformers import SwinModel\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for sampling \n",
    "num_samples = None\n",
    "\n",
    "# Params for Train_test_split \n",
    "train_test_split_rto = 0.1\n",
    "\n",
    "# Dataset\n",
    "window_size = 30\n",
    "predict_length = 7\n",
    "batch_size = 32\n",
    "\n",
    "# Model\n",
    "d_model = 128\n",
    "dropout = 0.3\n",
    "nhead = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "# d_model = 512\n",
    "# dropout = 0.3\n",
    "# nhead = 8\n",
    "# num_layers = 6\n",
    "# d_ff = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687004</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0663713001   \n",
       "1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0541518023   \n",
       "2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0505221004   \n",
       "3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687003   \n",
       "4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687004   \n",
       "\n",
       "      price  sales_channel_id  \n",
       "0  0.050831                 2  \n",
       "1  0.030492                 2  \n",
       "2  0.015237                 2  \n",
       "3  0.016932                 2  \n",
       "4  0.016932                 2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"HnM/transactions_train.csv\", dtype={\"article_id\":str}) # Read data\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104547\n",
      "104106\n",
      "104106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>product_life_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "      <td>./HnM/images/066/0663713001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2019-06-16</td>\n",
       "      <td>269 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "      <td>./HnM/images/054/0541518023.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>463 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "      <td>./HnM/images/050/0505221004.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>247 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>./HnM/images/068/0685687003.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>506 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687004</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>./HnM/images/068/0685687004.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>531 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_dat                                        customer_id  article_id  \\\n",
       "0 2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0663713001   \n",
       "1 2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0541518023   \n",
       "2 2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0505221004   \n",
       "3 2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687003   \n",
       "4 2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687004   \n",
       "\n",
       "      price  sales_channel_id                         img_path  is_valid  \\\n",
       "0  0.050831                 2  ./HnM/images/066/0663713001.jpg         1   \n",
       "1  0.030492                 2  ./HnM/images/054/0541518023.jpg         1   \n",
       "2  0.015237                 2  ./HnM/images/050/0505221004.jpg         1   \n",
       "3  0.016932                 2  ./HnM/images/068/0685687003.jpg         1   \n",
       "4  0.016932                 2  ./HnM/images/068/0685687004.jpg         1   \n",
       "\n",
       "    min_date   max_date product_life_length  \n",
       "0 2018-09-20 2019-06-16            269 days  \n",
       "1 2018-09-20 2019-12-27            463 days  \n",
       "2 2018-09-20 2019-05-25            247 days  \n",
       "3 2018-09-20 2020-02-08            506 days  \n",
       "4 2018-09-20 2020-03-04            531 days  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_presampling = df_raw.copy()\n",
    "print(df_presampling[\"article_id\"].nunique())\n",
    "\n",
    "# Filter out no image articles\n",
    "df_presampling[\"img_path\"] = df_presampling[\"article_id\"].apply(lambda x: f'./HnM/images/{x[:3]}/{x}.jpg') # Generate image path\n",
    "df_presampling[\"is_valid\"] = df_presampling[\"img_path\"].apply(lambda x: 1 if os.path.isfile(x) else 0) # Check whether the article has corresponding image file\n",
    "df_presampling = df_presampling[df_presampling[\"is_valid\"] == 1] # Filter out articles which do not have a corresponding image\n",
    "print(df_presampling[\"article_id\"].nunique())\n",
    "\n",
    "# # Filter out short product_lives\n",
    "df_presampling[\"t_dat\"] = pd.to_datetime(df_presampling[\"t_dat\"])\n",
    "df_presampling[\"min_date\"]= df_presampling.groupby(\"article_id\")[\"t_dat\"].transform(\"min\")\n",
    "df_presampling[\"max_date\"]= df_presampling.groupby(\"article_id\")[\"t_dat\"].transform(\"max\")\n",
    "df_presampling[\"product_life_length\"] = df_presampling[\"max_date\"] - df_presampling[\"min_date\"]\n",
    "# df_presampling = df_presampling[df_presampling[\"product_life_length\"].dt.days >= (window_size + predict_length)] # Product life length should be greater or equal than (window_size + predict_length)\n",
    "print(df_presampling[\"article_id\"].nunique())\n",
    "\n",
    "df_presampling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7418149, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0108775015</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0108775015</td>\n",
       "      <td>2018-09-21</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0108775015</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0108775015</td>\n",
       "      <td>2018-09-23</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0108775015</td>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id      t_dat  sales\n",
       "0  0108775015 2018-09-20     30\n",
       "1  0108775015 2018-09-21     48\n",
       "2  0108775015 2018-09-22     11\n",
       "3  0108775015 2018-09-23     26\n",
       "4  0108775015 2018-09-24     33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled = df_presampling.copy()\n",
    "\n",
    "# Sample by sales amount\n",
    "df_sampled = df_sampled.groupby([\"article_id\", \"t_dat\"], as_index=False).agg(sales=(\"price\", \"count\")) # Generate sales column\n",
    "sample_id_li = df_sampled.groupby(\"article_id\").agg({\"sales\":\"sum\"}).sort_values(\"sales\", ascending=False) # Sort article_id by number of sales\n",
    "sample_id_li = sample_id_li.iloc[:num_samples].index if num_samples else sample_id_li.index # Slice article_id\n",
    "df_sampled = df_sampled[df_sampled[\"article_id\"].isin(sample_id_li)].reset_index(drop=True)\n",
    "print(df_sampled.shape)\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_post = df_sampled.copy()\n",
    "\n",
    "# Explode dates\n",
    "def func(x):\n",
    "    full_date = pd.DataFrame(pd.date_range(x[\"t_dat\"].min(), x[\"t_dat\"].max(), freq=\"d\"), columns=[\"t_dat\"])\n",
    "    x = x.merge(full_date, on=\"t_dat\", how=\"right\").reset_index(drop=True)\n",
    "    x[\"article_id\"] = x[\"article_id\"].unique()[0]\n",
    "    x[\"sales\"] = x[\"sales\"].fillna(0)\n",
    "    return x\n",
    "df_post = df_post.groupby(\"article_id\", as_index=False).apply(lambda x: func(x)).reset_index(drop=True)\n",
    "df_post[\"time_idx\"] = df_post.groupby(\"article_id\").cumcount()\n",
    "\n",
    "### LabelEncode image path\n",
    "imgpath_encoder = LabelEncoder()\n",
    "df_post[\"img_path\"] = df_post[\"article_id\"].apply(lambda x: f'HnM/images/{x[:3]}/{x}.jpg')\n",
    "df_post[\"img_path\"] = imgpath_encoder.fit_transform(df_post[\"img_path\"])\n",
    "\n",
    "# Generate additional features\n",
    "df_post[\"year\"] = df_post[\"t_dat\"].dt.year\n",
    "df_post[\"month\"] = df_post[\"t_dat\"].dt.month\n",
    "df_post[\"day\"] = df_post[\"t_dat\"].dt.day\n",
    "\n",
    "# Train test split\n",
    "num_samples = num_samples if num_samples else df_post[\"article_id\"].nunique()\n",
    "num_train = int(np.round(num_samples * train_test_split_rto))\n",
    "sample_id_li_train = sample_id_li[:num_train]\n",
    "\n",
    "df_train = df_post[df_post[\"article_id\"].isin(sample_id_li_train)].reset_index(drop=True)\n",
    "df_valid = df_post[~df_post[\"article_id\"].isin(sample_id_li_train)].reset_index(drop=True)\n",
    "assert df_train.shape[0] + df_valid.shape[0] == df_post.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1281: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 34 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__img_path': 56214}, {'__group_id__img_path': 70577}, {'__group_id__img_path': 70578}, {'__group_id__img_path': 87643}, {'__group_id__img_path': 94011}, {'__group_id__img_path': 94523}, {'__group_id__img_path': 95081}, {'__group_id__img_path': 96078}, {'__group_id__img_path': 96766}, {'__group_id__img_path': 97343}]\n",
      "  warnings.warn(\n",
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1281: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 13919 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__img_path': 20}, {'__group_id__img_path': 31}, {'__group_id__img_path': 32}, {'__group_id__img_path': 38}, {'__group_id__img_path': 71}, {'__group_id__img_path': 85}, {'__group_id__img_path': 86}, {'__group_id__img_path': 89}, {'__group_id__img_path': 92}, {'__group_id__img_path': 93}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder\n",
    "train_dataset = pf.TimeSeriesDataSet(\n",
    "    data=df_train,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"sales\",\n",
    "    group_ids=[\"img_path\"],\n",
    "    # static_reals=[\"img_path\"], # image is a static information which does not change by time\n",
    "    min_encoder_length=window_size,\n",
    "    max_encoder_length=window_size,\n",
    "    min_prediction_idx=predict_length,\n",
    "    max_prediction_length=predict_length,\n",
    "    time_varying_known_reals=[\"sales\"],\n",
    "    # target_normalizer=None,\n",
    "    # scalers={\"img_path\":None}, # Since img_path is a set of labels encoded by external encoder, make it not to treat it as numbers\n",
    "    categorical_encoders={\"img_path\":NaNLabelEncoder(add_nan=True)}\n",
    ")\n",
    "valid_dataset = pf.TimeSeriesDataSet.from_dataset(train_dataset, df_post, predict=True, stop_randomization=True)\n",
    "\n",
    "train_dataloader = train_dataset.to_dataloader(batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = valid_dataset.to_dataloader(train=False, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_dataset.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(train_dataloader, \"train_dataloader.pkl\")\n",
    "joblib.dump(valid_dataloader, \"valid_dataloader.pkl\")\n",
    "joblib.dump(train_dataset, \"train_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "train_dataset = joblib.load(\"train_dataset.pkl\")\n",
    "train_dataloader = joblib.load(\"train_dataloader.pkl\")\n",
    "valid_dataloader = joblib.load(\"valid_dataloader.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "    # PE(pos, 2i) = sin(pos/10000^{2i/d_model}), \n",
    "    # PE(pos, 2i+1) = cos(pos/10000^{2i/d_model})\n",
    "    def __init__(self, max_len, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        position = torch.arange(max_len).reshape(-1,1).to(device)\n",
    "        i = torch.arange(d_model).to(device)//2\n",
    "        exp_term = 2*i/d_model\n",
    "        div_term = torch.pow(10000, exp_term).reshape(1, -1)\n",
    "        self.pos_encoded = position / div_term\n",
    "\n",
    "        self.pos_encoded[:, 0::2] = torch.sin(self.pos_encoded[:, 0::2])\n",
    "        self.pos_encoded[:, 1::2] = torch.cos(self.pos_encoded[:, 1::2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x + self.pos_encoded[:x.shape[1], :]\n",
    "        return self.dropout(output)\n",
    "    \n",
    "class Mask(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_padding_mask(self, arr):\n",
    "        res = torch.eq(arr, 0).type(torch.FloatTensor).to(device)\n",
    "        res = torch.where(res==1, -torch.inf, 0)\n",
    "        return res\n",
    "    \n",
    "    def get_lookahead_mask(self, arr):\n",
    "        seq_len = arr.shape[1]\n",
    "        mask = torch.triu(torch.ones((seq_len, seq_len))*-1e-9, 1).to(device)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, arr):\n",
    "        padding_mask = self.get_padding_mask(arr)\n",
    "        lookahead_mask = self.get_lookahead_mask(arr)\n",
    "        return padding_mask, lookahead_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalTransformer(torch.nn.Module):\n",
    "    def __init__(self, max_seq_len, d_model, dropout, nhead, d_ff, num_layers, swin_transformer):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc_mask = Mask()\n",
    "        self.linear1 = torch.nn.Linear(1, d_model)\n",
    "        self.enc_pos_encoding = PositionalEncoding(max_seq_len, d_model, dropout)\n",
    "        self.encoder = torch.nn.TransformerEncoder(torch.nn.TransformerEncoderLayer(d_model, nhead, d_ff, dropout, batch_first=True), num_layers)\n",
    "        \n",
    "        # Decoder\n",
    "        self.swin_transformer = swin_transformer\n",
    "        self.attn = torch.nn.MultiheadAttention(d_model, nhead, dropout, batch_first=True)\n",
    "        self.linear2 = torch.nn.Linear(self.swin_transformer..hconfigidden_size, d_model)\n",
    "        self.layernorm = torch.nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(d_model, d_model)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(d_model, d_model)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear3 = torch.nn.Linear(d_model*49, d_model)\n",
    "        self.linear4 = torch.nn.Linear(d_model, predict_length)\n",
    "    \n",
    "    def forward(self, enc_input, dec_input):\n",
    "        # Encoding\n",
    "        linear1_ = self.linear1(enc_input)\n",
    "        enc_pos_encoding_ = self.enc_pos_encoding(linear1_)\n",
    "        encoder_ = self.encoder(enc_pos_encoding_)\n",
    "        \n",
    "        # Decoding\n",
    "        ### Self attention\n",
    "        swin_transformer_ = self.swin_transformer(dec_input).last_hidden_state\n",
    "        linear2_ = self.linear2(swin_transformer_)\n",
    "\n",
    "        ### Cross attention\n",
    "        attn_, attn_weight = self.attn(query=linear2_, key=encoder_, value=encoder_)\n",
    "        layernorm_ = self.layernorm(linear2_ + attn_)\n",
    "\n",
    "        ### Feed forward\n",
    "        relu1_ = self.relu1(self.fc1(layernorm_))\n",
    "        relu2_ = self.relu2(self.fc2(relu1_))\n",
    "\n",
    "        # Final\n",
    "        flatten_ = self.flatten(relu2_)\n",
    "        linear3_ = self.linear3(flatten_)\n",
    "        linear4_ = self.linear4(linear3_)\n",
    "        \n",
    "        return linear4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalTransformerFromDataset(BaseModelWithCovariates):\n",
    "    def __init__(self, imgpath_encoder, predict_length, swin_transformer, window_size, d_model, dropout, nhead, d_ff, num_layers, \n",
    "                 static_categoricals, time_varying_categoricals_encoder, time_varying_categoricals_decoder, static_reals, \n",
    "                 time_varying_reals_encoder,  time_varying_reals_decoder, x_reals, x_categoricals, embedding_labels, embedding_paddings, \n",
    "                 categorical_groups, embedding_sizes, **kwargs):\n",
    "        self.save_hyperparameters()\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.imgpath_encoder = imgpath_encoder\n",
    "        self.predict_length = predict_length\n",
    "        self.network = MultimodalTransformer(window_size, d_model, dropout, nhead, d_ff, num_layers, swin_transformer)\n",
    "        # self.network.to(device)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        # Gather time series data\n",
    "        x = data[0][\"encoder_cont\"][:, :, 1].unsqueeze(-1) # shape: (batch_size, window_size, 1)\n",
    "        y = data[1][0] # shape: (batch_size, predict_length)\n",
    "\n",
    "        # Gather image data\n",
    "        img_path = data[0][\"encoder_cont\"][:, :, 0].type(torch.int).unique(dim=-1).squeeze() # Label encoded image_path → shape: (batch_size, ) \n",
    "        img_path = self.imgpath_encoder.inverse_transform(img_path) # The real image path e.g) 'HnM/images/068/0687169002.jpg' → shape: (batch_size, )\n",
    "\n",
    "        # Process image data\n",
    "        img_li = []\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]) # Transform image based on ImageNet standard\n",
    "\n",
    "        for n, path in enumerate(img_path): # Iterate images\n",
    "            img = transform(Image.open(path).convert(\"RGB\")) # Transform an image\n",
    "            img_li.append(img)\n",
    "        img_tensor = torch.stack(img_li, dim=0) # Put all the images together\n",
    "        \n",
    "        # Prediction\n",
    "        pred = self.network(x.to(device), img_tensor.to(device))\n",
    "        pred = self.transform_output(prediction=pred, target_scale=data[0][\"target_scale\"].to(device)) # Inverse transform the output\n",
    "        \n",
    "        return pred, y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'swin_transformer' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['swin_transformer'])`.\n",
      "  rank_zero_warn(\n",
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:197: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "swin_transformer = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\") # Get pre-trained SwinTransformer\n",
    "swin_transformer.to(device)\n",
    "\n",
    "model = MultimodalTransformerFromDataset.from_dataset(\n",
    "    train_dataset,\n",
    "    predict_length=predict_length,\n",
    "    swin_transformer=swin_transformer,\n",
    "    window_size=window_size,\n",
    "    d_model=d_model,\n",
    "    dropout=dropout,\n",
    "    nhead=nhead,\n",
    "    d_ff=d_ff,\n",
    "    num_layers=num_layers,\n",
    "    imgpath_encoder= imgpath_encoder\n",
    "    )\n",
    "model.to(device); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sh-sungho.park/Test/Paper/paper_v3.ipynb Cell 26\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_dataloader)\u001b[39m}\u001b[39;00m\u001b[39m → train_loss: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(train_loss_li)\u001b[39m}\u001b[39;00m\u001b[39m, valid_loss: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(valid_loss_li)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     mean_train_loss \u001b[39m=\u001b[39m train()\n",
      "\u001b[1;32m/home/sh-sungho.park/Test/Paper/paper_v3.ipynb Cell 26\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m); plot_bestsample(train_loss_raw, train_pred, train_y, n, \u001b[39m\"\u001b[39m\u001b[39mTRAIN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# plt.subplot(1,3,3); plot_bestsample(valid_loss_raw, valid_pred, valid_y, n, \"VALID\")\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m plt\u001b[39m.\u001b[39;49mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Report\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/paper_v3.ipynb#Z1016sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(train_dataloader)\u001b[39m}\u001b[39;00m\u001b[39m → train_loss: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(train_loss_li)\u001b[39m}\u001b[39;00m\u001b[39m, valid_loss: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(valid_loss_li)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         display(\n\u001b[1;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure,\n\u001b[1;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39;49m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    341\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/backend_bases.py:2346\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2346\u001b[0m         bbox_inches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mget_tightbbox(\n\u001b[1;32m   2347\u001b[0m             renderer, bbox_extra_artists\u001b[39m=\u001b[39;49mbbox_extra_artists)\n\u001b[1;32m   2348\u001b[0m         \u001b[39mif\u001b[39;00m pad_inches \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2349\u001b[0m             pad_inches \u001b[39m=\u001b[39m rcParams[\u001b[39m'\u001b[39m\u001b[39msavefig.pad_inches\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/figure.py:1776\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     artists \u001b[39m=\u001b[39m bbox_extra_artists\n\u001b[1;32m   1775\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m-> 1776\u001b[0m     bbox \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mget_tightbbox(renderer)\n\u001b[1;32m   1777\u001b[0m     \u001b[39mif\u001b[39;00m bbox \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1778\u001b[0m         bb\u001b[39m.\u001b[39mappend(bbox)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/axes/_base.py:4390\u001b[0m, in \u001b[0;36m_AxesBase.get_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[1;32m   4388\u001b[0m         \u001b[39mif\u001b[39;00m ba:\n\u001b[1;32m   4389\u001b[0m             bb\u001b[39m.\u001b[39mappend(ba)\n\u001b[0;32m-> 4390\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_title_position(renderer)\n\u001b[1;32m   4391\u001b[0m axbbox \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   4392\u001b[0m bb\u001b[39m.\u001b[39mappend(axbbox)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/axes/_base.py:2972\u001b[0m, in \u001b[0;36m_AxesBase._update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2970\u001b[0m top \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(top, bb\u001b[39m.\u001b[39mymax)\n\u001b[1;32m   2971\u001b[0m \u001b[39mif\u001b[39;00m title\u001b[39m.\u001b[39mget_text():\n\u001b[0;32m-> 2972\u001b[0m     ax\u001b[39m.\u001b[39;49myaxis\u001b[39m.\u001b[39;49mget_tightbbox(renderer)  \u001b[39m# update offsetText\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m     \u001b[39mif\u001b[39;00m ax\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39moffsetText\u001b[39m.\u001b[39mget_text():\n\u001b[1;32m   2974\u001b[0m         bb \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39moffsetText\u001b[39m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/axis.py:1337\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[1;32m   1335\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_ticks()\n\u001b[0;32m-> 1337\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_label_position(renderer)\n\u001b[1;32m   1339\u001b[0m \u001b[39m# go back to just this axis's tick labels\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m tlb1, tlb2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/axis.py:2619\u001b[0m, in \u001b[0;36mYAxis._update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2617\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2618\u001b[0m     spine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mspines[\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 2619\u001b[0m     spinebbox \u001b[39m=\u001b[39m spine\u001b[39m.\u001b[39;49mget_window_extent()\n\u001b[1;32m   2620\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   2621\u001b[0m     \u001b[39m# use Axes if spine doesn't exist\u001b[39;00m\n\u001b[1;32m   2622\u001b[0m     spinebbox \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mbbox\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/spines.py:158\u001b[0m, in \u001b[0;36mSpine.get_window_extent\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m bb\n\u001b[1;32m    157\u001b[0m bboxes \u001b[39m=\u001b[39m [bb]\n\u001b[0;32m--> 158\u001b[0m drawn_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[1;32m    160\u001b[0m major_tick \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m({\u001b[39m*\u001b[39mdrawn_ticks} \u001b[39m&\u001b[39m {\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mmajorTicks}), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    161\u001b[0m minor_tick \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m({\u001b[39m*\u001b[39mdrawn_ticks} \u001b[39m&\u001b[39m {\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mminorTicks}), \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/axis.py:1301\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks:\n\u001b[1;32m   1300\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1301\u001b[0m         loc_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_transform()\u001b[39m.\u001b[39;49mtransform(tick\u001b[39m.\u001b[39;49mget_loc())\n\u001b[1;32m   1302\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m         \u001b[39m# transforms.transform doesn't allow masked values but\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m         \u001b[39m# some scales might make them, so we need this try/except.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/matplotlib/transforms.py:2136\u001b[0m, in \u001b[0;36mIdentityTransform.transform\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m   2134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, points):\n\u001b[1;32m   2135\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[0;32m-> 2136\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masanyarray(points)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss_fn_ = torch.nn.MSELoss(reduction=\"none\")\n",
    "train_loss_li, valid_loss_li = [], []\n",
    "\n",
    "\n",
    "def plot_loss(train_loss_li, valid_loss_li):\n",
    "    plt.plot(train_loss_li, label=\"train\")\n",
    "    plt.plot(valid_loss_li, label=\"valid\")\n",
    "    plt.title(\"loss\")\n",
    "    plt.legend()\n",
    "\n",
    "def plot_bestsample(loss, pred, y, iter, msg):\n",
    "    loss = loss.mean(axis=1) # Shape: (batch_size, )\n",
    "    _, best_idx_li = torch.sort(loss)\n",
    "    for best_idx in best_idx_li:\n",
    "        # best_pred = torch.round(pred[best_idx])\n",
    "        best_pred = pred[best_idx]\n",
    "        best_pred = best_pred.cpu().detach().numpy() # Sales is always int → Shape: (predict_length, )\n",
    "        best_pred[best_pred < 0] = 0 # Sales never becomes negative\n",
    "        best_y = y[best_idx].cpu().detach().numpy()\n",
    "        if (np.max(best_y) < 10): # If predicted value is all 0, consider as not the best\n",
    "            continue\n",
    "        break\n",
    "    \n",
    "    plt.plot(best_pred, label=\"pred\")\n",
    "    plt.plot(best_y, label=\"y\", color=\"gray\", alpha=0.3)\n",
    "    plt.title(f\"{iter}th iter: Best example amongst {msg} dataset\")\n",
    "    plt.legend()\n",
    "\n",
    "def train():\n",
    "    total_train_loss, total_valid_loss = 0, 0\n",
    "    for n, (train_data, valid_data) in enumerate(zip(train_dataloader, valid_dataloader)):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Train\n",
    "        model.train(True)\n",
    "        optimizer.zero_grad()\n",
    "        train_pred, train_y = model(train_data)\n",
    "\n",
    "        # Get train loss\n",
    "        train_loss = loss_fn(train_pred, train_y) # Shape: (batch_size, predict_length)\n",
    "        train_loss.backward()\n",
    "        train_loss_raw = loss_fn_(train_pred, train_y)\n",
    "        total_train_loss += train_loss.item()\n",
    "        train_loss_li.append(total_train_loss/(n+1))\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        valid_pred, valid_y = model(valid_data)\n",
    "\n",
    "        # Get validation loss\n",
    "        valid_loss = loss_fn(valid_pred, valid_y)\n",
    "        valid_loss_raw = loss_fn_(valid_pred, valid_y)\n",
    "        total_valid_loss += valid_loss.item()\n",
    "        valid_loss_li.append(total_valid_loss/(n+1))\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(18,5))\n",
    "        plt.subplot(1,3,1); plot_loss(train_loss_li, valid_loss_li)\n",
    "        plt.subplot(1,3,2); plot_bestsample(train_loss_raw, train_pred, train_y, n, \"TRAIN\")\n",
    "        plt.subplot(1,3,3); plot_bestsample(valid_loss_raw, valid_pred, valid_y, n, \"VALID\")\n",
    "        plt.show()\n",
    "\n",
    "        # Report\n",
    "        print(f\"\\r {n}/{len(train_dataloader)} → train_loss: {np.mean(train_loss_li)}, valid_loss: {np.mean(valid_loss_li)}\", end=\"\")\n",
    "            \n",
    "for epoch in range(10):\n",
    "    mean_train_loss = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123510"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2818"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
