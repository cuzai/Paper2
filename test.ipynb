{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 3, 4]), tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])]\n",
      "____________________________________________________________________________________________________\n",
      "tensor([[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "____________________________________________________________________________________________________\n",
      "PackedSequence(data=tensor([ 1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  6,  6,  7,  7,\n",
      "         8,  8,  9,  9, 10, 11, 12, 13, 14]), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0]))\n",
      "____________________________________________________________________________________________________\n",
      "(tensor([[ 1,  2,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9,  0,  0,  0,  0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]]), tensor([ 4,  9, 14]))\n",
      "____________________________________________________________________________________________________\n",
      "tensor([4, 9, 0])\n"
     ]
    }
   ],
   "source": [
    "arr1 = torch.arange(1, 5)\n",
    "arr2 = torch.arange(1, 10)\n",
    "arr3 = torch.arange(1, 15)\n",
    "arr_raw = [arr1, arr2, arr3]\n",
    "\n",
    "# Padding\n",
    "arr = torch.nn.utils.rnn.pad_sequence(arr_raw, batch_first=True)\n",
    "mask = torch.where(arr==0, 1, 0) # If padding, then 1\n",
    "\n",
    "# Packing\n",
    "arr_len = [len(a) for a in arr_raw]\n",
    "arr_pack = torch.nn.utils.rnn.pack_padded_sequence(arr, arr_len, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "# Unpacking\n",
    "arr_unpack = torch.nn.utils.rnn.pad_packed_sequence(arr_pack, batch_first=True)\n",
    "\n",
    "# Get last index\n",
    "# last_idx = [torch.max(row) for row in mask]\n",
    "last_idx = torch.argmax(mask, dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "print(arr_raw); print(\"_\"*100)\n",
    "print(mask); print(\"_\"*100)\n",
    "print(arr_pack); print(\"_\"*100)\n",
    "print(arr_unpack); print(\"_\"*100)\n",
    "print(last_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m arr \u001b[38;5;241m=\u001b[39m [[torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]]\n\u001b[0;32m----> 5\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m arr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(arr, [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m6\u001b[39m], batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/torch/nn/utils/rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    395\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "arr = [torch.Tensor([0,0,0,1,2,3]).unsqueeze(-1), torch.Tensor([4,5,6,7,8,9]).unsqueeze(-1)]\n",
    "arr = torch.nn.utils.rnn.pad_sequence(arr, padding_value=0, batch_first=True)\n",
    "arr = torch.nn.utils.rnn.pack_padded_sequence(arr, [3,6], batch_first=True, enforce_sorted=False)\n",
    "\n",
    "model = torch.nn.LSTM(1, 3, batch_first=True)\n",
    "output, _ = model(arr)\n",
    "# output = arr\n",
    "\n",
    "output, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1]' is invalid for input of size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(lengths)\n\u001b[1;32m     18\u001b[0m packed_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(sequences, lengths, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/torch/nn/utils/rnn.py:332\u001b[0m, in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected total_length to be at least the length \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the longest sequence in input, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_length=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and max sequence length being \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m                          \u001b[38;5;241m.\u001b[39mformat(total_length, max_seq_length))\n\u001b[1;32m    331\u001b[0m     max_seq_length \u001b[38;5;241m=\u001b[39m total_length\n\u001b[0;32m--> 332\u001b[0m padded_output, lengths \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m unsorted_indices \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39munsorted_indices\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsorted_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1]' is invalid for input of size 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_lengths_left_padded(sequences, padding_value=0):\n",
    "    lengths = []\n",
    "    for seq in sequences:\n",
    "        # Find the index of the first non-padding value\n",
    "        first_non_pad = next((i for i, x in enumerate(seq) if x != padding_value), len(seq))\n",
    "        lengths.append(len(seq) - first_non_pad)\n",
    "    return lengths\n",
    "\n",
    "# Example usage\n",
    "sequences = torch.tensor([\n",
    "    [0, 0, 1, 2, 3],  # Left-padded sequence\n",
    "    [0, 0, 0, 4, 5]\n",
    "])\n",
    "lengths = calculate_lengths_left_padded(sequences)\n",
    "print(lengths)\n",
    "packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(sequences, lengths, enforce_sorted=False)\n",
    "torch.nn.utils.rnn.pad_packed_sequence(packed_sequences, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_lengths_left_padded(sequences, padding_value=0):\n",
    "    lengths = []\n",
    "    for seq in sequences:\n",
    "        first_non_pad = next((i for i, x in enumerate(seq) if x != padding_value), len(seq))\n",
    "        lengths.append(len(seq) - first_non_pad)\n",
    "    return lengths\n",
    "\n",
    "# Example usage\n",
    "sequences = torch.tensor([\n",
    "    [0, 0, 1, 2, 3],  # Left-padded sequence\n",
    "    [0, 0, 0, 4, 5]\n",
    "], dtype=torch.long)  # Ensure the correct data type\n",
    "\n",
    "lengths = calculate_lengths_left_padded(sequences)\n",
    "packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(sequences, lengths, batch_first=True, enforce_sorted=False)\n",
    "padded_output, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(packed_sequences, batch_first=True)\n",
    "\n",
    "print(padded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
