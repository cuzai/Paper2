{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Torch-related\n",
    "import torch\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "# Custom defined\n",
    "from config import fine_tuning\n",
    "from libs.data import load_dataset, collate_fn, Dataset\n",
    "from architecture.architecture import MaskedBlockAutoencoder\n",
    "from architecture.shared_module import patchify, unpatchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales torch.Size([2, 146, 1])\n",
      "day torch.Size([2, 146])\n",
      "dow torch.Size([2, 146])\n",
      "month torch.Size([2, 146])\n",
      "holiday torch.Size([2, 146])\n",
      "price torch.Size([2, 146, 1])\n",
      "temporal_padding_mask torch.Size([2, 146])\n",
      "target_fcst_mask torch.Size([2, 146])\n",
      "img_path torch.Size([2, 3, 224, 224])\n",
      "detail_desc torch.Size([2, 7])\n",
      "detail_desc_revert_padding_mask torch.Size([2, 8])\n",
      "detail_desc_remain_idx torch.Size([2, 7])\n",
      "detail_desc_masked_idx torch.Size([2, 0])\n",
      "detail_desc_revert_idx torch.Size([2, 7])\n"
     ]
    }
   ],
   "source": [
    "is_test_mode = True\n",
    "is_new_rawdata = False\n",
    "is_new_dataset = False\n",
    "config = fine_tuning\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if is_new_dataset:\n",
    "    train_dataset = load_dataset(is_test_mode, is_new_rawdata, config, mode=\"fine_tuning\", verbose=True)\n",
    "else:\n",
    "    suffix = \"_test\" if is_test_mode else \"\"\n",
    "    train_dataset = torch.load(f\"src/fine_tuning_dataset{suffix}\")\n",
    "\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, config), pin_memory=True, num_workers=16, prefetch_factor=32)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, config))\n",
    "for _ in train_dataloader:\n",
    "    [print(key, val.shape) for key, val in _.items() if \"scaler\" not in key and \"raw\" not in key]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------\n",
      "   Parent Layers       Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================================\n",
      "      Forecaster      MBAEEncoder-1                          19,232,640      19,157,376\n",
      "=======================================================================================\n",
      "Total params: 19,232,640\n",
      "Trainable params: 19,157,376\n",
      "Non-trainable params: 75,264\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"saved_model_epoch9_2024-05-24 19:04:47.683949\"\n",
    "label_encoder_dict = joblib.load(\"./src/label_encoder_dict.pkl\")\n",
    "\n",
    "mbae_model = MaskedBlockAutoencoder(config, label_encoder_dict)\n",
    "# mbae_model.load_state_dict(torch.load(path))\n",
    "\n",
    "class Forecaster(torch.nn.Module):\n",
    "    def __init__(self, config, mbae_model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.mbae_encoder = mbae_model.encoder\n",
    "    \n",
    "    def forward(self, data_input, device):\n",
    "        data_dict, idx_dict, mask_dict = self.to_gpu(data_input, device)\n",
    "        self.mbae_encoder(data_dict, idx_dict, mask_dict, device)\n",
    "        return\n",
    "    \n",
    "    def to_gpu(self, data_input, device):\n",
    "        data_dict, idx_dict, mask_dict = {}, {}, {}\n",
    "        data_cols = self.config.temporal_cols + self.config.img_cols + self.config.nlp_cols\n",
    "        for key, val in data_input.items():\n",
    "            if key in data_cols:\n",
    "                data_dict[key] = data_input[key].to(device)\n",
    "            elif key.endswith(\"idx\"):\n",
    "                idx_dict[key] = data_input[key].to(device)\n",
    "            elif key.endswith(\"mask\"):\n",
    "                mask_dict[key] = data_input[key].to(device)\n",
    "            \n",
    "        return data_dict, idx_dict, mask_dict\n",
    "\n",
    "model  = Forecaster(config, mbae_model)\n",
    "model.to(device)\n",
    "summary(model, _, device, show_parent_layers=True, print_summary=True)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
