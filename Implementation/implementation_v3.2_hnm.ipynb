{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"\n",
    "Desciption\n",
    "- Visuelle products\n",
    "- Not use of pytorch_forecasting\n",
    "- year, month, day, dayofweek as positional embedding feature\n",
    "- Extract attention from MY transformer but not from image model's\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n",
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd; pd.set_option(\"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import SwinModel, SwinConfig, ViTModel, ViTConfig, Mask2FormerModel, Mask2FormerConfig\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb1304f6110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling parameter\n",
    "n_smaples = None\n",
    "\n",
    "# Data parameter\n",
    "random_state = 0\n",
    "pred_len = 30\n",
    "batch_size = 32\n",
    "valid_start_date = \"2020-06-01\"\n",
    "\n",
    "# Model hyperparameter\n",
    "d_model = 128; d_model = 256; d_model = 512\n",
    "nhead = 4; nhead = 8\n",
    "d_ff = 256; d_ff = 512; d_ff = 1024\n",
    "dropout = 0.3; dropout = 0.3\n",
    "num_layers = 4; num_layers = 6\n",
    "\n",
    "# Seed set\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read transaction\n",
    "df_trans = pd.read_csv(\"../HnM/transactions_train.csv\", parse_dates=[\"t_dat\"], dtype={\"article_id\":str})\n",
    "df_train_raw = df_trans[df_trans[\"t_dat\"] < valid_start_date]\n",
    "df_valid_raw = df_trans[df_trans[\"t_dat\"] >= valid_start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id\n",
       "ffffd9ac14e89946416d80e791d064701994755c3ab686a1eaf3458c36f52241       1\n",
       "73f988e71aa96456022c21f0fc62e78bcf7d97b5646b33883b231dd37d88204b       1\n",
       "73f9a9dd9f5f3249685206fd12ac93b68c206a8c56fbd95eb767fa0dccde0892       1\n",
       "11fa5af0b08a07eaf538044849db18130d706ca031a01c413af285e5e7b4d35b       1\n",
       "73f9ca9e633c23ff9da2dbccbc687e092abdd375d4baa087209305378561f082       1\n",
       "                                                                    ... \n",
       "cd04ec2726dd58a8c753e0d6423e57716fd9ebcf2f14ed6012e7e5bea016b4d6    1237\n",
       "a65f77281a528bf5c1e9f270141d601d116e1df33bf9df512f495ee06647a9cc    1361\n",
       "49beaacac0c7801c2ce2d189efe525fe80b5d37e46ed05b50a4cd88e34d0748f    1364\n",
       "b4db5e5259234574edfff958e170fe3a5e13b6f146752ca066abca3c156acc71    1441\n",
       "be1981ab818cf4ef6765b2ecaea7a2cbf14ccd6e8a7ee985513d9e8e53c6d91b    1895\n",
       "Length: 1362281, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans.groupby(\"customer_id\").size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = data.copy()\n",
    "    data = data.groupby([\"article_id\", \"t_dat\"], as_index=False).agg(sales=(\"customer_id\",\"size\"), price=(\"price\",\"mean\"))\n",
    "\n",
    "    # Expand date\n",
    "    def func(x):\n",
    "        article_id = x[\"article_id\"].iloc[0]\n",
    "        max_date = x[\"t_dat\"].max()\n",
    "        y_start_date = max_date - pd.DateOffset(days=pred_len)\n",
    "        dateref = pd.DataFrame(pd.date_range(y_start_date, max_date, freq=\"d\"), columns=[\"t_dat\"])\n",
    "        x = pd.merge(dateref, x, on=\"t_dat\", how=\"outer\")\n",
    "        x = x.sort_values(\"t_dat\")\n",
    "        x[\"sales\"] = x[\"sales\"].fillna(0)\n",
    "        x[\"price\"] = x[\"price\"].fillna(method=\"ffill\")\n",
    "        x[\"article_id\"] = article_id\n",
    "        return x\n",
    "    data = data.groupby(\"article_id\", as_index=False).apply(lambda x: func(x)).reset_index(drop=True)\n",
    "\n",
    "    # Make date positions\n",
    "    data[\"year\"] = data[\"t_dat\"].dt.year\n",
    "    data[\"month\"] = data[\"t_dat\"].dt.month - 1\n",
    "    data[\"week\"] = data[\"t_dat\"].dt.isocalendar().week - 1\n",
    "    data[\"day\"] = data[\"t_dat\"].dt.day -1\n",
    "    data[\"dayofweek\"] = data[\"t_dat\"].dt.dayofweek\n",
    "    \n",
    "    # Aggregate with list\n",
    "    data = data.groupby([\"article_id\"], as_index=False)[[\"sales\", \"price\", \"year\", \"month\", \"week\", \"day\", \"dayofweek\"]].agg(lambda x: list(x))\n",
    "    data[\"size\"] = data[\"sales\"].str.len()\n",
    "    data = data[data[\"size\"] > pred_len+1]\n",
    "\n",
    "    # Read article info\n",
    "    df_article = pd.read_csv(\"../HnM/articles.csv\", dtype={\"article_id\":str})\n",
    "    df_article = df_article[[\"article_id\"] + [col for col in df_article.columns if \"name\" in col]]\n",
    "\n",
    "    # Merge two datasets\n",
    "    df_raw = pd.merge(data, df_article, on=\"article_id\")\n",
    "    print(f\"Original: {df_raw.shape}\")\n",
    "\n",
    "    # Filter valid length\n",
    "    df_prep = df_raw.copy()\n",
    "    df_prep = df_prep[df_prep[\"size\"] > pred_len]\n",
    "    print(f\"Valid sized: {df_prep.shape}\")\n",
    "\n",
    "    # Sampling\n",
    "    if n_smaples:\n",
    "        samples = df_prep[\"article_id\"].unique()\n",
    "        df_prep = df_prep[df_prep[\"article_id\"].isin(samples[:n_smaples])]\n",
    "        print(f\"{min(n_smaples, df_prep['article_id'].nunique())} sampled: {df_prep.shape}\")\n",
    "\n",
    "    # Encode imgpath\n",
    "    encoder = LabelEncoder()\n",
    "    df_prep[\"img_path\"] = df_prep[\"article_id\"].apply(lambda x: f'../HnM/images/{x[:3]}/{x}.jpg') # Generate image path\n",
    "    df_prep[\"is_valid\"] = df_prep[\"img_path\"].apply(lambda x: 1 if os.path.isfile(x) else 0) # Check whether the article has corresponding image file\n",
    "    df_prep = df_prep[df_prep[\"is_valid\"] == 1].drop(\"is_valid\", axis=1) # Valid if having corresponding image\n",
    "    print(f\"Valid imaged:\", df_prep.shape)\n",
    "\n",
    "    return df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: (83078, 21)\n",
      "Valid sized: (83078, 21)\n",
      "Valid imaged: (82725, 22)\n",
      "____________________________________________________________________________________________________\n",
      "Original: (31030, 21)\n",
      "Valid sized: (31030, 21)\n",
      "Valid imaged: (30984, 22)\n"
     ]
    }
   ],
   "source": [
    "df_train_prep = preprocess(df_train_raw); print(\"_\"*100)\n",
    "df_valid_prep = preprocess(df_valid_raw)\n",
    "\n",
    "# Save\n",
    "df_train_prep.to_parquet(\"df_train_prep.parquet\")\n",
    "df_valid_prep.to_parquet(\"df_valid_prep.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep = pd.read_parquet(\"df_train_prep.parquet\")\n",
    "df_valid_prep = pd.read_parquet(\"df_valid_prep.parquet\")\n",
    "\n",
    "# df_train_prep = df_train_prep[~df_train_prep[\"product_type_name\"].isin(exclude_li)]\n",
    "# df_valid_prep = df_valid_prep[~df_valid_prep[\"product_type_name\"].isin(exclude_li)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 573, 1])\n",
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 573, 1])\n",
      "torch.Size([32, 573])\n",
      "torch.Size([32, 573])\n",
      "torch.Size([32, 573])\n",
      "torch.Size([32, 573])\n",
      "torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.sales = data[\"sales\"].values\n",
    "        self.img = data[\"img_path\"].values\n",
    "        self.year = data[\"year\"].values\n",
    "        self.month = data[\"month\"].values\n",
    "        self.week = data[\"week\"].values\n",
    "        self.day = data[\"day\"].values\n",
    "        self.dayofweek = data[\"dayofweek\"].values\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sales_raw = self.sales[idx]\n",
    "        \n",
    "        # Scaling\n",
    "        # scaler = MinMaxScaler()\n",
    "        # sales_raw = scaler.fit_transform(sales_raw.reshape(-1,1)).reshape(-1) + 1\n",
    "        sales_raw = np.log1p(sales_raw)\n",
    "\n",
    "        # Process features\n",
    "        sales = sales_raw[:-pred_len]\n",
    "        y = sales_raw[-pred_len:]\n",
    "\n",
    "        img = Image.open(self.img[idx]).convert(\"RGB\")\n",
    "        img_tensor = self.transform(img).numpy()\n",
    "\n",
    "        year = self.year[idx][:-pred_len]\n",
    "        month = self.month[idx][:-pred_len]\n",
    "        week = self.week[idx][:-pred_len]\n",
    "        day = self.day[idx][:-pred_len]\n",
    "        dayofweek = self.dayofweek[idx][:-pred_len]        \n",
    "\n",
    "        return sales, img, img_tensor, year, month, week, day, dayofweek, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.img.shape[0]\n",
    "\n",
    "train_dataset = Dataset(df_train_prep)\n",
    "valid_dataset = Dataset(df_valid_prep)\n",
    "\n",
    "def func(data):\n",
    "    sales = np.nan_to_num(to_time_series_dataset([sales_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data]), nan=0).squeeze()\n",
    "\n",
    "    img = ([img_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data])\n",
    "    img_tensor = np.array([img_tensor_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data])\n",
    "\n",
    "    year = np.nan_to_num(to_time_series_dataset([year_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data]), nan=0).squeeze()\n",
    "    month = np.nan_to_num(to_time_series_dataset([month_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data]), nan=0).squeeze()\n",
    "    week = np.nan_to_num(to_time_series_dataset([week_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data]), nan=0).squeeze()\n",
    "    day = np.nan_to_num(to_time_series_dataset([day_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data]), nan=0).squeeze()\n",
    "    dayofweek = np.nan_to_num(to_time_series_dataset([dayofweek_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data]), nan=0).squeeze()\n",
    "    \n",
    "    y = np.array([y_ for sales_, img_, img_tensor_, year_, month_, week_, day_, dayofweek_, y_ in data])\n",
    "\n",
    "    sales = torch.FloatTensor(sales).unsqueeze(-1)\n",
    "    img_tensor = torch.FloatTensor(img_tensor)\n",
    "\n",
    "    year = torch.FloatTensor(year).unsqueeze(-1)\n",
    "    month = torch.IntTensor(month)\n",
    "    week = torch.IntTensor(week)\n",
    "    day = torch.IntTensor(day)\n",
    "    dayofweek = torch.IntTensor(dayofweek)\n",
    "\n",
    "    y = torch.FloatTensor(y)\n",
    "\n",
    "    return sales, img, img_tensor, year, month, week, day, dayofweek, y\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=8, prefetch_factor=8, shuffle=True, collate_fn=func)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=8, prefetch_factor=8, collate_fn=func)\n",
    "\n",
    "for sales, img, img_tensor, year, month, week, day, dayofweek, y in train_dataloader:\n",
    "    print(sales.shape)\n",
    "    print(img_tensor.shape)\n",
    "    print(year.shape)\n",
    "    print(month.shape)\n",
    "    print(week.shape)\n",
    "    print(day.shape)\n",
    "    print(dayofweek.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "verbose = False\n",
    "\n",
    "class Mask(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_padding_mask(self, arr):\n",
    "        res = torch.eq(arr, 0).type(torch.FloatTensor)\n",
    "        res = torch.where(res==1, True, False)\n",
    "        return res\n",
    "    \n",
    "    def get_lookahead_mask(self, arr):\n",
    "        seq_len = arr.shape[1]\n",
    "        mask = torch.triu(torch.ones((seq_len, seq_len))*-torch.inf, 1)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, arr):\n",
    "        padding_mask = self.get_padding_mask(arr)\n",
    "        lookahead_mask = self.get_lookahead_mask(arr)\n",
    "        return padding_mask.to(device), lookahead_mask.to(device)\n",
    "\n",
    "class PositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        # Raw embedder\n",
    "        self.year_embedder = torch.nn.Linear(1, d_model)\n",
    "        self.month_embedder = torch.nn.Embedding(num_embeddings=12, embedding_dim=d_model)\n",
    "        \n",
    "        # Concatenate\n",
    "        self.layer_norm1 = torch.nn.LayerNorm(d_model*2)\n",
    "        self.linear1 = torch.nn.Linear(d_model*2, d_model)\n",
    "\n",
    "        # Feed forward concatenated positions\n",
    "        self.linear2 = torch.nn.Linear(d_model, d_model)\n",
    "        self.activation1 = torch.nn.ELU()\n",
    "        self.linear3 = torch.nn.Linear(d_model, d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        # Residual\n",
    "        self.layer_norm2 = torch.nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, year, month):\n",
    "        # Raw embedder\n",
    "        year_embedding = self.year_embedder(year)\n",
    "        month_embedding = self.month_embedder(month)\n",
    "\n",
    "        # Concatenate\n",
    "        concat = torch.concat([year_embedding, month_embedding], dim=-1)\n",
    "        concat = self.linear1(self.layer_norm1(concat))\n",
    "\n",
    "        # Feed forward\n",
    "        linear = self.activation1(self.linear2(concat))\n",
    "        linear = self.dropout(self.linear3(linear))\n",
    "\n",
    "        # Residual\n",
    "        output = self.layer_norm2(concat + linear)\n",
    "\n",
    "        return output\n",
    "\n",
    "class CustomEncoderLayer(torch.nn.TransformerEncoderLayer):\n",
    "    def __init__(self, d_model, nhead, d_ff, dropout, batch_first):\n",
    "        super().__init__(d_model, nhead, d_ff, dropout, batch_first=True)\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None, is_causal=False):\n",
    "        src_key_padding_mask = F._canonical_mask(\n",
    "            mask=src_key_padding_mask,\n",
    "            mask_name=\"src_key_padding_mask\",\n",
    "            other_type=F._none_or_dtype(src_mask),\n",
    "            other_name=\"src_mask\",\n",
    "            target_type=src.dtype\n",
    "        )\n",
    "\n",
    "        src_mask = F._canonical_mask(\n",
    "            mask=src_mask,\n",
    "            mask_name=\"src_mask\",\n",
    "            other_type=None,\n",
    "            other_name=\"\",\n",
    "            target_type=src.dtype,\n",
    "            check_other=False,\n",
    "        )\n",
    "\n",
    "        # see Fig. 1 of https://arxiv.org/pdf/2002.04745v1.pdf\n",
    "        why_not_sparsity_fast_path = ''\n",
    "        if not src.dim() == 3:\n",
    "            why_not_sparsity_fast_path = f\"input not batched; expected src.dim() of 3 but got {src.dim()}\"\n",
    "        elif self.training:\n",
    "            why_not_sparsity_fast_path = \"training is enabled\"\n",
    "        elif not self.self_attn.batch_first :\n",
    "            why_not_sparsity_fast_path = \"self_attn.batch_first was not True\"\n",
    "        elif not self.self_attn._qkv_same_embed_dim :\n",
    "            why_not_sparsity_fast_path = \"self_attn._qkv_same_embed_dim was not True\"\n",
    "        elif not self.activation_relu_or_gelu:\n",
    "            why_not_sparsity_fast_path = \"activation_relu_or_gelu was not True\"\n",
    "        elif not (self.norm1.eps == self.norm2.eps):\n",
    "            why_not_sparsity_fast_path = \"norm1.eps is not equal to norm2.eps\"\n",
    "        elif src.is_nested and (src_key_padding_mask is not None or src_mask is not None):\n",
    "            why_not_sparsity_fast_path = \"neither src_key_padding_mask nor src_mask are not supported with NestedTensor input\"\n",
    "        elif self.self_attn.num_heads % 2 == 1:\n",
    "            why_not_sparsity_fast_path = \"num_head is odd\"\n",
    "        elif torch.is_autocast_enabled():\n",
    "            why_not_sparsity_fast_path = \"autocast is enabled\"\n",
    "        if not why_not_sparsity_fast_path:\n",
    "            tensor_args = (\n",
    "                src,\n",
    "                self.self_attn.in_proj_weight,\n",
    "                self.self_attn.in_proj_bias,\n",
    "                self.self_attn.out_proj.weight,\n",
    "                self.self_attn.out_proj.bias,\n",
    "                self.norm1.weight,\n",
    "                self.norm1.bias,\n",
    "                self.norm2.weight,\n",
    "                self.norm2.bias,\n",
    "                self.linear1.weight,\n",
    "                self.linear1.bias,\n",
    "                self.linear2.weight,\n",
    "                self.linear2.bias,\n",
    "            )\n",
    "\n",
    "            # We have to use list comprehensions below because TorchScript does not support\n",
    "            # generator expressions.\n",
    "            _supported_device_type = [\"cpu\", \"cuda\"]\n",
    "            if torch.overrides.has_torch_function(tensor_args):\n",
    "                why_not_sparsity_fast_path = \"some Tensor argument has_torch_function\"\n",
    "            elif not all((x.device.type in _supported_device_type) for x in tensor_args):\n",
    "                why_not_sparsity_fast_path = (\"some Tensor argument's device is neither one of \"\n",
    "                                            f\"{_supported_device_type}\")\n",
    "            elif torch.is_grad_enabled() and any(x.requires_grad for x in tensor_args):\n",
    "                why_not_sparsity_fast_path = (\"grad is enabled and at least one of query or the \"\n",
    "                                            \"input/output projection weights or biases requires_grad\")\n",
    "\n",
    "            if not why_not_sparsity_fast_path:\n",
    "                merged_mask, mask_type = self.self_attn.merge_masks(src_mask, src_key_padding_mask, src)\n",
    "                return torch._transformer_encoder_layer_fwd(\n",
    "                    src,\n",
    "                    self.self_attn.embed_dim,\n",
    "                    self.self_attn.num_heads,\n",
    "                    self.self_attn.in_proj_weight,\n",
    "                    self.self_attn.in_proj_bias,\n",
    "                    self.self_attn.out_proj.weight,\n",
    "                    self.self_attn.out_proj.bias,\n",
    "                    self.activation_relu_or_gelu == 2,\n",
    "                    self.norm_first,\n",
    "                    self.norm1.eps,\n",
    "                    self.norm1.weight,\n",
    "                    self.norm1.bias,\n",
    "                    self.norm2.weight,\n",
    "                    self.norm2.bias,\n",
    "                    self.linear1.weight,\n",
    "                    self.linear1.bias,\n",
    "                    self.linear2.weight,\n",
    "                    self.linear2.bias,\n",
    "                    merged_mask,\n",
    "                    mask_type,\n",
    "                )\n",
    "\n",
    "\n",
    "        x = src\n",
    "        print(\"x.shape\", x.shape)\n",
    "        print(\"src_key_padding_mask.shape\", src_key_padding_mask.shape)\n",
    "        if self.norm_first:\n",
    "            x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)\n",
    "            x = x + self._ff_block(self.norm2(x))\n",
    "        else:\n",
    "            x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))\n",
    "            x = self.norm2(x + self._ff_block(x))\n",
    "        print(\"x.shape\", x.shape)\n",
    "        return x\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, dropout, d_model, nhead, d_ff, num_layers):\n",
    "        super().__init__()\n",
    "        # Positional encoding\n",
    "        self.sales_embedder = torch.nn.Linear(1, d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        # Encoding\n",
    "        # self.encoder = torch.nn.TransformerEncoder(torch.nn.TransformerEncoderLayer(d_model, nhead, d_ff, dropout, batch_first=True), num_layers)\n",
    "        self.encoder = torch.nn.TransformerEncoder(CustomEncoderLayer(d_model, nhead, d_ff, dropout, batch_first=True), num_layers)\n",
    "    \n",
    "    def forward(self, sales, positional_embedding, enc_padding_mask):\n",
    "        # Positional encoding\n",
    "        sales_embedding = self.sales_embedder(sales)\n",
    "        sales_embedding = self.dropout(sales_embedding + positional_embedding)\n",
    "\n",
    "        # Encoding\n",
    "        print(\"sales_embedding.shape\", sales_embedding.shape)\n",
    "        encoding = self.encoder(sales_embedding, src_key_padding_mask=enc_padding_mask)\n",
    "        print(\"encoding.shape\", encoding.shape)\n",
    "        return encoding\n",
    "\n",
    "class CustomDecoderLayer(torch.nn.TransformerDecoderLayer):\n",
    "    def __init__(self, d_model, nhead, d_ff, dropout, batch_first=True):\n",
    "        super().__init__(d_model, nhead, d_ff, dropout, batch_first=True)\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal=False, memory_is_causal=False):\n",
    "        x = tgt\n",
    "        if self.norm_first:\n",
    "            # sa_output, attn = self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n",
    "            x = x\n",
    "            attn_output = self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask, memory_is_causal)\n",
    "            x = x + attn_output\n",
    "            x = x + self._ff_block(self.norm3(x))\n",
    "        else:\n",
    "            # sa_output, attn = self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n",
    "            # x = self.norm1(x + sa_output)\n",
    "            attn_output = self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask, memory_is_causal)\n",
    "            x = x + attn_output\n",
    "            x = self.norm3(x + self._ff_block(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    # multihead attention block\n",
    "    def _mha_block(self, x, mem, attn_mask, key_padding_mask, is_causal=False):\n",
    "        # print(\"x.shape\", x.shape)\n",
    "        # print(\"mem.shape\", mem.shape)\n",
    "        # print(\"key_padding_mask.shape\", key_padding_mask.shape)\n",
    "        x = self.multihead_attn(x, mem, mem,\n",
    "                                attn_mask=attn_mask,\n",
    "                                key_padding_mask=key_padding_mask,\n",
    "                                is_causal=is_causal,\n",
    "                                need_weights=False)[0]\n",
    "        # print(attn.sum(-1))\n",
    "        return self.dropout2(x)\n",
    "\n",
    "    # self-attention block\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask, is_causal=False):\n",
    "        x = self.self_attn(x, x, x,\n",
    "                           attn_mask=attn_mask,\n",
    "                           key_padding_mask=key_padding_mask,\n",
    "                           is_causal=is_causal,\n",
    "                           need_weights=False)[0]\n",
    "        return self.dropout1(x)\n",
    "\n",
    "class CustomDecoder(torch.nn.TransformerDecoder):\n",
    "    def __init__(self, decoder_layer, num_layers, norm=None):\n",
    "        super().__init__(decoder_layer, num_layers, norm)\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        output = tgt\n",
    "        for mod in self.layers:\n",
    "            output = mod(output, memory, tgt_mask=tgt_mask, memory_mask=memory_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
    "\n",
    "        if self.norm:\n",
    "            output = self.norm(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, d_model, nhead, d_ff, dropout, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_seq = 197 # Vit: 197, Swin: 49\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Image model train\n",
    "        self.img_model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "        # self.img_model = ViTModel(ViTConfig())\n",
    "        # self.img_model = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "        # self.img_model = SwinModel(SwinConfig())\n",
    "        # self.img_model = Mask2FormerModel.from_pretrained(\"facebook/mask2former-swin-small-coco-instance\")\n",
    "        # self.img_model = Mask2FormerModel(Mask2FormerConfig())\n",
    "        \n",
    "        # Image model embedding\n",
    "        self.img_embedder = torch.nn.Linear(self.img_model.config.hidden_size, d_model)\n",
    "        self.img_linear = torch.nn.Linear(d_model, d_model)\n",
    "        self.img_activation = torch.nn.ELU()\n",
    "\n",
    "        # Decoding\n",
    "        self.decoder = CustomDecoder(CustomDecoderLayer(d_model, nhead, d_ff, dropout, batch_first=True), num_layers)\n",
    "        # self.decoder = torch.nn.TransformerDecoder(torch.nn.TransformerDecoderLayer(d_model, nhead, d_ff, dropout, batch_first=True), num_layers)\n",
    "    \n",
    "    def forward(self, img_tensor, encoder_output, enc_padding_mask):\n",
    "        # Image embedding\n",
    "        img_hidden_state, pooler_output, img_attn = self.img_model(img_tensor, output_attentions=True).values() # ViT, SwinTransformer\n",
    "        # encoder_last_hidden_state, pixel_decoder_last_hidden_state, transformer_decoder_last_hidden_state, masks_queries_logits, attn_weight = self.img_model(pixel_values=img_tensor, pixel_mask=img_mask, output_attentions=True).values() # For Mask2Former\n",
    "        img_embedding = self.img_activation(self.img_linear(self.img_embedder(img_hidden_state)))\n",
    "        \n",
    "        # print(\"img_embedding.shape\", img_embedding.shape)\n",
    "        # print(\"encoder_output.shape\", encoder_output.shape)\n",
    "        # print(\"enc_padding_mask.shape\", enc_padding_mask.shape)\n",
    "        dec_output = self.decoder(tgt=img_embedding, memory=encoder_output, memory_key_padding_mask=enc_padding_mask)\n",
    "        return dec_output, img_attn\n",
    "\n",
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout, nhead, d_ff, num_layers, pred_len):\n",
    "        super().__init__()\n",
    "        # Post process\n",
    "        self.enc_mask = Mask()\n",
    "        self.positional_embedder = PositionalEmbedding(d_model, dropout)\n",
    "\n",
    "        # Encoder-Decoder\n",
    "        self.encoder = Encoder(dropout, d_model, nhead, d_ff, num_layers)\n",
    "        self.decoder = Decoder(d_model, nhead, d_ff, dropout, num_layers)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(d_model, d_model)\n",
    "        # self.linear1 = torch.nn.Linear(d_model*100, d_model)\n",
    "        self.elu1 = torch.nn.ELU()\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, sales, img_tensor, year, month, week, day, dayofweek):\n",
    "        # Post process\n",
    "        enc_padding_mask, _ = self.enc_mask(sales.squeeze(-1))\n",
    "        positional_embedding = self.positional_embedder(year, month)\n",
    "\n",
    "        encoder_output = self.encoder(sales, positional_embedding, enc_padding_mask)\n",
    "        decoder_output, attn_li = self.decoder(img_tensor, encoder_output, enc_padding_mask)\n",
    "        output = self.elu1(self.linear1(decoder_output))\n",
    "        output = self.linear2(output)[:, :pred_len, :].squeeze()\n",
    "        \n",
    "        return output, attn_li\n",
    "\n",
    "model = Transformer(d_model, dropout, nhead, d_ff, num_layers, pred_len)\n",
    "# model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0:0/2586 mean_train_loss: 0.012974460422992707 -- mean_val_loss: 0sales_embedding.shape torch.Size([32, 277, 512])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 277])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 277])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 277])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 277])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 277])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 277])\n",
      "x.shape torch.Size([32, 277, 512])\n",
      "encoding.shape torch.Size([32, 277, 512])\n",
      " 0:1/2586 mean_train_loss: 1.1095225848257542 -- mean_val_loss: 0sales_embedding.shape torch.Size([32, 254, 512])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 254])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 254])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 254])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 254])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 254])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 254])\n",
      "x.shape torch.Size([32, 254, 512])\n",
      "encoding.shape torch.Size([32, 254, 512])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb Cell 20\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(e, val_loss, train_loss_li, val_loss_li) \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39m# val_loss = val(e)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     train_loss_li\u001b[39m.\u001b[39mappend(train_loss)\n",
      "\u001b[1;32m/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: plot_sample(np\u001b[39m.\u001b[39mexpm1(y), np\u001b[39m.\u001b[39mexpm1(pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Report\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cudatest/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "def plot_sample(y, pred):\n",
    "    # Plot sample\n",
    "    clear_output(wait=True)\n",
    "    y_sample = y[-1]\n",
    "    pred_sample = pred[-1].detach().cpu()\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_loss_li, label=\"train\")\n",
    "    plt.plot(val_loss_li, label=\"valid\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(y_sample, label=\"y\")\n",
    "    plt.plot(pred_sample, label=\"pred\")\n",
    "    plt.title(\"Sample\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def train(epoch, val_loss, train_loss_li, val_loss_li):\n",
    "    model.train()\n",
    "    total_len = len(train_dataloader)\n",
    "    loss_li = []\n",
    "    for n, data in enumerate(train_dataloader):\n",
    "        sales, img, img_tensor, year, month, week, day, dayofweek, y = data\n",
    "        \n",
    "        # Train\n",
    "        optimizer.zero_grad()\n",
    "        pred, attn_weight = model(sales.to(device), img_tensor.to(device), year.to(device), month.to(device), week.to(device), day.to(device), dayofweek.to(device))\n",
    "        pred = pred.squeeze()\n",
    "\n",
    "        # plot sample\n",
    "        if not verbose: \n",
    "            if n % 10 == 0: plot_sample(np.expm1(y), np.expm1(pred.detach().cpu()))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Report\n",
    "        loss_li.append(loss.item())\n",
    "        mean_loss = np.mean(loss_li[-10:]) / 10\n",
    "        if not verbose: print(f\"\\r {epoch}:{n}/{total_len} mean_train_loss: {mean_loss} -- mean_val_loss: {val_loss}\", end=\"\")\n",
    "\n",
    "    print()\n",
    "    return mean_loss\n",
    "\n",
    "def val(epoch):\n",
    "    model.eval()\n",
    "    total_len = len(valid_dataloader)\n",
    "    total_loss = 0\n",
    "    for n, data in enumerate(valid_dataloader):\n",
    "        sales, img, img_tensor, season, category, extra, year, month, y = data\n",
    "        \n",
    "        # Pred\n",
    "        with torch.no_grad():\n",
    "            pred, attn_weight = model(sales.to(device), img_tensor.to(device), img_mask.to(device), season.to(device), category.to(device), extra.to(device), year.to(device), month.to(device))\n",
    "            pred = pred.squeeze()\n",
    "            loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "            # Report\n",
    "            total_loss += loss.item()\n",
    "            mean_loss = total_loss / (n+1)\n",
    "            print(f\"\\r {epoch}:{n}/{total_len} mean_val_loss: {mean_loss}\", end=\"\")\n",
    "\n",
    "    print()\n",
    "    return mean_loss\n",
    " \n",
    "epoch = 5\n",
    "train_loss_li, val_loss_li = [0], [0]\n",
    "val_loss = 0\n",
    "\n",
    "for e in range(epoch):\n",
    "    train_loss = train(e, val_loss, train_loss_li, val_loss_li) # Train\n",
    "    # val_loss = val(e)\n",
    "\n",
    "    train_loss_li.append(train_loss)\n",
    "    val_loss_li.append(val_loss)\n",
    "    torch.save(model.state_dict(), f\"model_{np.mean(train_loss)}_{np.mean(val_loss)}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_embedding.shape torch.Size([32, 429, 512])\n",
      "encoding.shape torch.Size([32, 429, 512])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, SwinModel, SwinForImageClassification, ViTModel, ViTForImageClassification\n",
    "import matplotlib.cm as cm\n",
    "from gradcam import GradCAM\n",
    "from gradcam.utils import visualize_cam\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))\n",
    "# model.eval()\n",
    "# model.train()\n",
    "\n",
    "# for data in valid_dataloader:\n",
    "for data in train_dataloader:\n",
    "    sales, img, img_tensor, year, month, week, day, dayofweek, y = data\n",
    "    with torch.no_grad():\n",
    "        pred, attn_weight = model(sales.to(device), img_tensor.to(device), year.to(device), month.to(device), week.to(device), day.to(device), dayofweek.to(device))\n",
    "        # loss = loss_fn(pred, y.to(device)).item()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12, 197, 197])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_map(img, att_mat, get_mask=False):\n",
    "    att_mat = torch.stack(att_mat).squeeze(1)\n",
    "\n",
    "    # Average the attention weights across all heads.\n",
    "    att_mat = torch.mean(att_mat, dim=1)\n",
    "    print(\"att_mat.shape:\", att_mat.shape)\n",
    "    # att_mat = torch.max(att_mat, dim=1).values\n",
    "\n",
    "    # To account for residual connections, we add an identity matrix to the attention matrix and re-normalize the weights.\n",
    "    residual_att = torch.eye(att_mat.size(1))\n",
    "    aug_att_mat = att_mat + residual_att\n",
    "    aug_att_mat = aug_att_mat / aug_att_mat.sum(dim=-1).unsqueeze(-1)\n",
    "\n",
    "    # Recursively multiply the weight matrices\n",
    "    joint_attentions = torch.zeros(aug_att_mat.size())\n",
    "    joint_attentions[0] = aug_att_mat[0]\n",
    "\n",
    "    for n in range(1, aug_att_mat.size(0)):\n",
    "        joint_attentions[n] = torch.matmul(aug_att_mat[n], joint_attentions[n-1])\n",
    "\n",
    "    print(\"joint_attentions.shape:\", joint_attentions.shape)\n",
    "    v = joint_attentions[-1]\n",
    "    print(\"v.shape:\", v.shape)\n",
    "    grid_size = int(np.sqrt(aug_att_mat.size(-1)))\n",
    "    print(\"grid_size.shape:\", grid_size)\n",
    "    print(v[0, 1:].shape)\n",
    "    mask = v[0, 1:].reshape(grid_size, grid_size).detach().numpy()\n",
    "    # mask = v[0].reshape(grid_size, grid_size).detach().numpy()\n",
    "    if get_mask:\n",
    "        result = cv2.resize(mask / mask.max(), img.size)\n",
    "    else:        \n",
    "        mask = cv2.resize(mask / mask.max(), img.size)[..., np.newaxis]\n",
    "        result = (mask * img).astype(\"uint8\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_attention_map(img, att_mat, get_mask=False):\n",
    "    # Average the attention weights across all heads.\n",
    "    att_mat = [torch.mean(i, dim=1) for i in att_mat]\n",
    "    att_mat = torch.concat(att_mat, dim=0)\n",
    "    \n",
    "    # att_mat = torch.max(att_mat, dim=1).values\n",
    "\n",
    "    # To account for residual connections, we add an identity matrix to the attention matrix and re-normalize the weights.\n",
    "    residual_att = torch.eye(att_mat.size(1))\n",
    "    aug_att_mat = att_mat + residual_att\n",
    "    aug_att_mat = aug_att_mat / aug_att_mat.sum(dim=-1).unsqueeze(-1)\n",
    "\n",
    "    # Recursively multiply the weight matrices\n",
    "    joint_attentions = torch.zeros(aug_att_mat.size())\n",
    "    joint_attentions[0] = aug_att_mat[0]\n",
    "\n",
    "    for n in range(1, aug_att_mat.size(0)):\n",
    "        joint_attentions[n] = torch.matmul(aug_att_mat[n], joint_attentions[n-1])\n",
    "\n",
    "    print(\"joint_attentions.shape:\", joint_attentions.shape)\n",
    "    v = joint_attentions[-1]\n",
    "    print(\"v.shape:\", v.shape)\n",
    "    grid_size = int(np.sqrt(aug_att_mat.size(-1)))\n",
    "    print(\"grid_size.shape:\", grid_size)\n",
    "    print(v[0, 1:].shape)\n",
    "    mask = v[0, 1:].reshape(grid_size, grid_size).detach().numpy()\n",
    "    # mask = v[0].reshape(grid_size, grid_size).detach().numpy()\n",
    "    if get_mask:\n",
    "        result = cv2.resize(mask / mask.max(), img.size)\n",
    "    else:        \n",
    "        mask = cv2.resize(mask / mask.max(), img.size)[..., np.newaxis]\n",
    "        result = (mask * img).astype(\"uint8\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def plot_attention_map(original_img, att_map, loss):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(5, 5))\n",
    "    ax1.set_title('Original')\n",
    "    ax2.set_title(loss)\n",
    "    _ = ax1.imshow(original_img)\n",
    "    _ = ax2.imshow(att_map, cmap = cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_embedding.shape torch.Size([32, 375, 512])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 375])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 375])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 375])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 375])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 375])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "src_key_padding_mask.shape torch.Size([32, 375])\n",
      "x.shape torch.Size([32, 375, 512])\n",
      "encoding.shape torch.Size([32, 375, 512])\n",
      "joint_attentions.shape: torch.Size([384, 197, 197])\n",
      "v.shape: torch.Size([197, 197])\n",
      "grid_size.shape: 14\n",
      "torch.Size([196])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     pred, attn_weight \u001b[39m=\u001b[39m model(sales\u001b[39m.\u001b[39mto(device), img_tensor\u001b[39m.\u001b[39mto(device), year\u001b[39m.\u001b[39mto(device), month\u001b[39m.\u001b[39mto(device), week\u001b[39m.\u001b[39mto(device), day\u001b[39m.\u001b[39mto(device), dayofweek\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     res \u001b[39m=\u001b[39m get_attention_map(img, \u001b[39mtuple\u001b[39;49m(i\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu() \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m attn_weight), get_mask\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     plot_attention_map(img[\u001b[39m0\u001b[39m], res, loss)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# get_myattention(attn_weight, img_)\u001b[39;00m\n",
      "\u001b[1;32m/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# mask = v[0].reshape(grid_size, grid_size).detach().numpy()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m get_mask:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m     result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(mask \u001b[39m/\u001b[39m mask\u001b[39m.\u001b[39mmax(), img\u001b[39m.\u001b[39;49msize)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39melse\u001b[39;00m:        \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu.isdow.com/home/sh-sungho.park/Test/Paper/Implementation/implementation_v3.2_hnm.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     mask \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(mask \u001b[39m/\u001b[39m mask\u001b[39m.\u001b[39mmax(), img\u001b[39m.\u001b[39msize)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, np\u001b[39m.\u001b[39mnewaxis]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, SwinModel, SwinForImageClassification, ViTModel, ViTForImageClassification\n",
    "import matplotlib.cm as cm\n",
    "from gradcam import GradCAM\n",
    "from gradcam.utils import visualize_cam\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "# model.eval()\n",
    "model.train()\n",
    "\n",
    "# for data in valid_dataloader:\n",
    "for data in train_dataloader:\n",
    "    sales, img, img_tensor, year, month, week, day, dayofweek, y = data\n",
    "    with torch.no_grad():\n",
    "        pred, attn_weight = model(sales.to(device), img_tensor.to(device), year.to(device), month.to(device), week.to(device), day.to(device), dayofweek.to(device))\n",
    "        res = get_attention_map(img, tuple(i.detach().cpu() for i in attn_weight), get_mask=True)\n",
    "        plot_attention_map(img[0], res, loss)\n",
    "        # get_myattention(attn_weight, img_)\n",
    "        plt.show()\n",
    "        input()\n",
    "        clear_output(wait=True)\n",
    "        time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
