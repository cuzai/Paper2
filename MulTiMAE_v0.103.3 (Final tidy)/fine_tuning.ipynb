{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Torch-related\n",
    "import torch\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "# Custom defined\n",
    "from config import fine_tuning\n",
    "from libs.data import load_dataset, collate_fn\n",
    "from architecture.architecture import MaskedBlockAutoencoder\n",
    "from architecture.shared_module import patchify, unpatchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2381.77it/s]\n",
      "100%|██████████| 112213/112213 [00:04<00:00, 26581.59it/s]\n",
      "/home/sh-sungho.park/anaconda3/envs/cudatest/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales torch.Size([32, 300, 1])\n",
      "day torch.Size([32, 300])\n",
      "dow torch.Size([32, 300])\n",
      "month torch.Size([32, 300])\n",
      "holiday torch.Size([32, 300])\n",
      "price torch.Size([32, 300, 1])\n",
      "target_fcst_mask torch.Size([32, 300])\n",
      "temporal_padding_mask torch.Size([32, 300])\n",
      "img_path torch.Size([32, 3, 224, 224])\n",
      "detail_desc torch.Size([32, 82])\n",
      "detail_desc_revert_padding_mask torch.Size([32, 83])\n",
      "detail_desc_remain_idx torch.Size([32, 82])\n",
      "detail_desc_masked_idx torch.Size([32, 0])\n",
      "detail_desc_revert_idx torch.Size([32, 82])\n",
      "information torch.Size([32, 32])\n",
      "information_revert_padding_mask torch.Size([32, 33])\n",
      "information_remain_idx torch.Size([32, 32])\n",
      "information_masked_idx torch.Size([32, 0])\n",
      "information_revert_idx torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "is_test_mode = False\n",
    "is_new_dataset = True\n",
    "config = fine_tuning\n",
    "device = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "if is_new_dataset:\n",
    "    train_dataset = load_dataset(is_test_mode, None, config, mode=\"fine_tuning\", verbose=True)\n",
    "else:\n",
    "    suffix = \"_test\" if is_test_mode else \"\"\n",
    "    train_dataset = torch.load(f\"src/fine_tuning_train_dataset{suffix}\")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, config), pin_memory=True, num_workers=16, prefetch_factor=32)\n",
    "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, config))\n",
    "for _ in train_dataloader:\n",
    "    [print(key, val.shape) for key, val in _.items() if \"scaler\" not in key and \"raw\" not in key]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"saved_model_epoch2_2024-05-08 12:48:39.442299\"\n",
    "label_encoder_dict = joblib.load(\"./src/label_encoder_dict.pkl\")\n",
    "\n",
    "mbae_encoder = MaskedBlockAutoencoder(config, label_encoder_dict)\n",
    "mbae_encoder.load_state_dict(torch.load(path))\n",
    "# mbae_encoder = mbae_encoder.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbae_encoder.to(device)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mse_loss = torch.nn.MSELoss(reduction=\"none\")\n",
    "ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "def get_loss(pred_dict, y_dict, idx_dict, padding_mask_dict):\n",
    "    loss_dict = {}\n",
    "    loss_sum, cnt = 0, 0\n",
    "\n",
    "    for n, (key, pred) in enumerate(pred_dict.items()):\n",
    "        y = y_dict[key].to(device)\n",
    "\n",
    "        # Compute loss\n",
    "        ### Temporal loss\n",
    "        if key in config.temporal_cols:\n",
    "            if key in config.scaling_cols:\n",
    "                loss = mse_loss(pred, y).squeeze()\n",
    "            elif key in config.embedding_cols:\n",
    "                loss = ce_loss(pred.view(-1, pred.shape[-1]), y.view(-1).to(torch.long))\n",
    "                loss = loss.view(y.shape)\n",
    "        ### Img loss\n",
    "        elif key in config.img_cols:\n",
    "            pred = pred[:, 1:, :]\n",
    "            y = patchify(y, config.patch_size)\n",
    "            loss = mse_loss(pred, y)\n",
    "        ### Nlp loss\n",
    "        elif key in config.nlp_cols:\n",
    "            pred = pred[:, 1:, :]\n",
    "            loss = ce_loss(pred.reshape(-1, pred.shape[-1]), y.reshape(-1).to(torch.long))\n",
    "            loss = loss.view(y.shape)\n",
    "        \n",
    "        # Masking loss\n",
    "        ### Temporal\n",
    "        if key in config.temporal_cols:\n",
    "            masked_idx = idx_dict[\"temporal_masked_idx\"]\n",
    "            padding_mask = padding_mask_dict[\"temporal_padding_mask\"]\n",
    "\n",
    "            total_mask = torch.where((padding_mask==1), 1, 0)\n",
    "            loss *= total_mask\n",
    "            loss_sum += loss.sum(); cnt += total_mask.sum()\n",
    "            loss = loss.sum()/total_mask.sum()\n",
    "        ### Img\n",
    "        elif key in config.img_cols:\n",
    "            loss_sum += loss.sum(); cnt += loss.shape[0]*loss.shape[1]*loss.shape[2]\n",
    "            loss = loss.mean()\n",
    "        ### Nlp\n",
    "        elif key in config.nlp_cols:\n",
    "            padding_mask = padding_mask_dict[f\"{key}_revert_padding_mask\"][:, 1:]\n",
    "            loss *= padding_mask\n",
    "\n",
    "            loss_sum += loss.sum(); cnt += total_mask.sum()\n",
    "            loss = loss.sum() / padding_mask.sum()\n",
    "            \n",
    "        loss_dict[key] = loss\n",
    "    \n",
    "    total_loss = loss_sum / cnt\n",
    "    return loss_dict, total_loss\n",
    "\n",
    "def obtain_loss_dict_for_plot(total_loss, loss_dict, loss_li_dict, mean_loss_li_dict):\n",
    "    loss_li_dict[\"total\"].append(total_loss.item())\n",
    "    mean_loss_li_dict[\"total\"].append(np.array(loss_li_dict[\"total\"]).mean())\n",
    "\n",
    "    for key, val in loss_dict.items():\n",
    "        loss_li_dict[key].append(val.item())\n",
    "        mean_loss_li_dict[key].append(np.array(loss_li_dict[key]).mean())\n",
    "\n",
    "    return loss_li_dict, mean_loss_li_dict\n",
    "\n",
    "def plot_sample(nrows, ncols, config, mean_loss_li_dict, output_dict, data_dict, decoding_weight_dict):\n",
    "    idx, plot_idx = 0, 1\n",
    "    for key, val in mean_loss_li_dict.items():\n",
    "        # Individual loss\n",
    "        plt.subplot(nrows, ncols, plot_idx)\n",
    "        plt.plot(val)\n",
    "        plt.title(f\"{key}: {val[-1]}\")\n",
    "        plot_idx += 1; \n",
    "        if key==\"total\": \n",
    "            plot_idx += 3; continue\n",
    "\n",
    "        pred, y = output_dict[key].detach().cpu().squeeze(), data_dict[key].squeeze()\n",
    "        length_dict = {\"temporal\" if key in config.temporal_cols else key :val.shape[1] for key, val in decoding_weight_dict.items()}\n",
    "        \n",
    "        # Temporal sample\n",
    "        if key in config.temporal_cols:\n",
    "            ### Sample\n",
    "            if key in config.embedding_cols: pred = torch.argmax(pred, dim=-1)\n",
    "            plt.subplot(nrows, ncols, plot_idx)\n",
    "            plt.plot(y[idx]); plt.plot(pred[idx])\n",
    "            ### Weight\n",
    "            decoder_weight = decoding_weight_dict[key][idx].mean(dim=0).detach().cpu()\n",
    "            # decoder_weight = decoding_weight_dict[key][idx].min(dim=0).values.detach().cpu()\n",
    "            ###### Temporal\n",
    "            img_decoder_weight = decoder_weight[length_dict[\"temporal\"]:length_dict[\"temporal\"]+length_dict[\"img_path\"]]\n",
    "            img_decoder_weight = img_decoder_weight[1:]\n",
    "            plt.subplot(nrows, ncols, plot_idx+1)\n",
    "            plt.imshow(img_decoder_weight.reshape(224//config.patch_size, 224//config.patch_size))\n",
    "            ###### Nlp\n",
    "            os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "            nlp_decoder_weight1 = decoder_weight[length_dict[\"temporal\"]+length_dict[\"img_path\"]:length_dict[\"temporal\"]+length_dict[\"img_path\"]+length_dict[\"detail_desc\"]]\n",
    "            nlp_decoder_weight2 = decoder_weight[length_dict[\"temporal\"]+length_dict[\"img_path\"]+length_dict[\"detail_desc\"]:]\n",
    "            nlp_decoder_weight = torch.cat([nlp_decoder_weight1[1:], nlp_decoder_weight2[1:]], dim=-1)\n",
    "\n",
    "            nlp1 = tokenizer.tokenize(tokenizer.decode(data_dict[\"detail_desc\"][idx]))\n",
    "            nlp2 = tokenizer.tokenize(tokenizer.decode(data_dict[\"information\"][idx]))\n",
    "            # nlp2 = []\n",
    "            text = nlp1 + nlp2\n",
    "\n",
    "            df = pd.DataFrame({\"text\":text, \"weight\":nlp_decoder_weight})\n",
    "            df = df[df[\"text\"]!=\"[PAD]\"]\n",
    "            plt.subplot(nrows, ncols, plot_idx+2)\n",
    "            sns.barplot(df[\"weight\"])\n",
    "            plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n",
    "\n",
    "        # Img sample\n",
    "        elif key in config.img_cols:\n",
    "            pred = unpatchify(pred[:, 1:, :]).permute(0,2,3,1)\n",
    "            y = y.permute(0,2,3,1)\n",
    "            \n",
    "            plt.subplot(nrows, ncols, plot_idx)\n",
    "            plt.imshow(data_dict[\"img_path_raw\"][idx].permute(1,2,0))\n",
    "\n",
    "            plt.subplot(nrows, ncols, plot_idx+1)\n",
    "            plt.imshow(y[idx])\n",
    "\n",
    "            plt.subplot(nrows, ncols, plot_idx+2)\n",
    "            plt.imshow(pred[idx])\n",
    "\n",
    "        # Nlp sample\n",
    "        elif key in config.nlp_cols:\n",
    "            pred = tokenizer.decode(torch.argmax(pred, dim=-1)[idx])\n",
    "            y = tokenizer.decode(y[idx])\n",
    "        \n",
    "        plot_idx += 3\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_epoch(model, optimizer, dataloader, config, e):\n",
    "    pbar = tqdm(dataloader)\n",
    "    loss_li_dict, mean_loss_li_dict = defaultdict(list), defaultdict(list)\n",
    "    model.eval()\n",
    "\n",
    "    for n, data in enumerate(pbar):\n",
    "        with torch.no_grad():\n",
    "            decoding_output_dict, encoding_weight_dict, decoding_weight_dict, idx_dict, padding_mask_dict = mbae_encoder(data, device)\n",
    "        loss_dict, loss = get_loss(decoding_output_dict, data, idx_dict, padding_mask_dict)\n",
    "\n",
    "        # Plot\n",
    "        if n % 20 == 0:\n",
    "            nrows, ncols = 11, 4\n",
    "            plt.figure(figsize=(25,25))\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            loss_li_dict, mean_loss_li_dict = obtain_loss_dict_for_plot(loss, loss_dict, loss_li_dict, mean_loss_li_dict)\n",
    "            plot_sample(nrows, ncols, config, mean_loss_li_dict, decoding_output_dict, data, decoding_weight_dict)\n",
    "\n",
    "1==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_100876/1349275816.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n",
      "/tmp/ipykernel_100876/1349275816.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n",
      "/tmp/ipykernel_100876/1349275816.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n",
      "/tmp/ipykernel_100876/1349275816.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n",
      "/tmp/ipykernel_100876/1349275816.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n",
      "/tmp/ipykernel_100876/1349275816.py:122: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plt.gca().set_xticklabels(df[\"text\"], rotation=90)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(mbae_encoder.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "epoch = 10\n",
    "\n",
    "epoch_loss = {}\n",
    "for e in range(epoch):\n",
    "    loss = train_epoch(mbae_encoder, optimizer, train_dataloader, config, e)\n",
    "    scheduler.step()\n",
    "    epoch_loss[e] = loss\n",
    "\n",
    "    # # Save model\n",
    "    # if not is_test_mode:\n",
    "    #     now = datetime.datetime.now()\n",
    "    #     path = f\"./saved_model_epoch{e}_{now}\"\n",
    "    #     torch.save(mbae_encoder.state_dict(), path)\n",
    "\n",
    "print(epoch_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
